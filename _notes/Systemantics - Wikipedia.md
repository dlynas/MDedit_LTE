---
source: en.wikipedia.org
url: https://en.wikipedia.org/wiki/Systemantics
---

From Wikipedia, the free encyclopedia

<table><caption>General Systemantics<span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=General+Systemantics&amp;rft.author=%5B%5BJohn+Gall+%28author%29%7CJohn+Gall%5D%5D&amp;rft.date=1975%2F78%2C+1986%2C+2002&amp;rft.pub=General+Systemantics+Press"></span></caption><tbody><tr><td colspan="2"><span typeof="mw:File/Frameless"><a href="https://en.wikipedia.org/wiki/File:Systemantics.jpg"><img src="https://upload.wikimedia.org/wikipedia/en/thumb/e/e3/Systemantics.jpg/220px-Systemantics.jpg" decoding="async" width="220" height="322" srcset="https://upload.wikimedia.org/wikipedia/en/e/e3/Systemantics.jpg 1.5x" data-file-width="263" data-file-height="385"></a></span><p>1977 edition</p></td></tr><tr><th scope="row">Author</th><td><a href="https://en.wikipedia.org/wiki/John_Gall_(author)" title="John Gall (author)">John Gall</a></td></tr><tr><th scope="row">Illustrator</th><td>R. O. Blechman</td></tr><tr><th scope="row">Language</th><td>English</td></tr><tr><th scope="row">Subject</th><td><a href="https://en.wikipedia.org/wiki/Systems_science" title="Systems science">Systems science</a></td></tr><tr><th scope="row">Publisher</th><td>General Systemantics Press</td></tr><tr><th scope="row"><p>Publication date</p></th><td>1975/78, 1986, 2002</td></tr><tr><th scope="row">Media&nbsp;type</th><td>Print</td></tr></tbody></table>

_**General Systemantics**_ (retitled to _**Systemantics**_ in its second edition and _**The Systems Bible**_ in its third) is a [systems engineering](https://en.wikipedia.org/wiki/Systems_engineering "Systems engineering") treatise by [John Gall](https://en.wikipedia.org/wiki/John_Gall_(author) "John Gall (author)") in which he offers practical principles of systems design based on experience and anecdotes.

It is offered from the perspective of how _not_ to design systems, based on system engineering failures. The primary precept of the treatise is that large [complex systems](https://en.wikipedia.org/wiki/Complex_system "Complex system") are extremely difficult to design correctly despite best intentions, so care must be taken to design smaller, less-complex systems and to do so with incremental functionality based on close and continual touch with user needs and measures of effectiveness.

## History\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=1 "Edit section: History")\]

The book was initially self-published after Gall received rejection letters from 30 publishers. After several reviews in academic journals, it was picked up by [Quadrangle–The New York Times Book Company](https://en.wikipedia.org/wiki/Quadrangle/The_New_York_Times_Book_Company "Quadrangle/The New York Times Book Company"), who published it in 1977.<sup id="cite_ref-1"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-1">[1]</a></sup> A condensed version was also published in _[The New York Times](https://en.wikipedia.org/wiki/The_New_York_Times "The New York Times")_ prior to the book's publication.<sup id="cite_ref-2"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-2">[2]</a></sup>

## Title origin\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=2 "Edit section: Title origin")\]

The term _**systemantics**_ is a commentary on prior work by [Alfred Korzybski](https://en.wikipedia.org/wiki/Alfred_Korzybski "Alfred Korzybski") called [general semantics](https://en.wikipedia.org/wiki/General_semantics "General semantics") which conjectured that all systems failures could be attributed to a single root cause – a failure to communicate. Gall observes that, instead, system failure is an _intrinsic feature of systems_. He thereby derives the term _general systemantics_ in deference to the notion of a sweeping theory of system failure, but attributed to an intrinsic feature based on laws of system behavior. He observes as a side-note that system antics also playfully captures the concept that systems naturally "act up."<sup id="cite_ref-FOOTNOTEGall197824_3-0"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-FOOTNOTEGall197824-3">[3]</a></sup>

## Contents\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=3 "Edit section: Contents")\]

### Background\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=4 "Edit section: Background")\]

#### Premise\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=5 "Edit section: Premise")\]

-   Systems in general work poorly or not at all.<sup id="cite_ref-FOOTNOTEGall197822_4-0"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-FOOTNOTEGall197822-4">[4]</a></sup>

This is more a universal observation than a law. The origin of this observation is traced back via:

1.  [Murphy's Law](https://en.wikipedia.org/wiki/Murphy%27s_Law "Murphy's Law") that "if anything can go wrong, it will",
2.  [Alfred Korzybski's](https://en.wikipedia.org/wiki/Korzybski "Korzybski") [general semantics](https://en.wikipedia.org/wiki/General_semantics "General semantics") notion of failure's root cause being a communication problem,
3.  Humorist [Stephen Potter's](https://en.wikipedia.org/wiki/Stephen_Potter "Stephen Potter") [One-upmanship](https://en.wikipedia.org/wiki/One-upmanship "One-upmanship") on ways to "game" the system for personal benefit,
4.  Historian [C. Northcote Parkinson's](https://en.wikipedia.org/wiki/C._Northcote_Parkinson "C. Northcote Parkinson") principle called [Parkinson's Law](https://en.wikipedia.org/wiki/Parkinson%27s_Law "Parkinson's Law") – "Work expands so as to fill the time available for its completion"
5.  Educator [Lawrence J. Peter's](https://en.wikipedia.org/wiki/Laurence_J._Peter "Laurence J. Peter") widely cited [Peter Principle](https://en.wikipedia.org/wiki/Peter_Principle "Peter Principle") – "In a hierarchy every employee tends to rise to his level of incompetence ... in time every post tends to be occupied by an employee who is incompetent to carry out its duties ... Work is accomplished by those employees who have not yet reached their level of incompetence."

#### Scope\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=6 "Edit section: Scope")\]

By _systems_, the author refers to those that "...involve human beings, particularly those very large systems such as national governments, nations themselves, religions, the railway system, the post office..." though the intention is that the principles are general to any system.<sup id="cite_ref-FOOTNOTEGall197826_5-0"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-FOOTNOTEGall197826-5">[5]</a></sup>

Additionally, the author observes:

1.  Everything is a system.
2.  Everything is part of a larger system.
3.  The universe is infinitely systematized, both upward (larger systems) and downward (smaller systems).
4.  All systems are infinitely complex.

### First principles\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=7 "Edit section: First principles")\]

-   New systems mean new problems.<sup id="cite_ref-FOOTNOTEGall197829_6-0"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-FOOTNOTEGall197829-6">[6]</a></sup>

Once a system is set up to solve some problem, the system itself engenders new problems relating to its development, operations and maintenance. The author points out that the additional energy required to support the system can consume the energy it was meant to save. This leads to the next principle:

-   The total amount of _anergy_ in the universe is fixed.

The author defines _anergy_ as the effort required to bring about a change. This is meant as a tongue-in-cheek analog of the law of conservation of energy.

-   Systems tend to expand to fill the known universe.

One of the problems that a system creates is that it becomes an entity unto itself that not only persists but expands and encroaches on areas beyond the original system's purview.

### Why systems behave poorly\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=8 "Edit section: Why systems behave poorly")\]

-   Complicated systems produce unexpected outcomes (Generalized Uncertainty Principle).<sup id="cite_ref-FOOTNOTEGall197840_7-0"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-FOOTNOTEGall197840-7">[7]</a></sup>

The author cites a number of spectacular unexpected behaviors including:

1.  The [Aswan Dam](https://en.wikipedia.org/wiki/Aswan_Dam "Aswan Dam") diverting the [Nile](https://en.wikipedia.org/wiki/Nile "Nile") River's fertilizing sediment to [Lake Nasser](https://en.wikipedia.org/wiki/Lake_Nasser "Lake Nasser") (where it is useless) requiring the dam to operate at full electrical generating capacity to run the artificial fertilizer plants needed to replace the diverted sediment.
2.  The space [Vehicle Assembly Building](https://en.wikipedia.org/wiki/Vehicle_Assembly_Building "Vehicle Assembly Building") at [Kennedy Space Center](https://en.wikipedia.org/wiki/Kennedy_Space_Center "Kennedy Space Center") designed to protect vehicles from weather is so large that it produces its own weather.

### Feedback\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=9 "Edit section: Feedback")\]

Not only do systems expand well beyond their original goals, but as they evolve they tend to oppose even their own original goals. This is seen as a systems theory analog of [Le Chatelier's principle](https://en.wikipedia.org/wiki/Le_Chatelier%27s_principle "Le Chatelier's principle") that suggests chemical and physical processes tend to counteract changed conditions that upset equilibrium until a new equilibrium is established. This same counteraction force can be seen in systems behavior. For example, incentive reward systems set up in business can have the effect of institutionalizing mediocrity.<sup id="cite_ref-[Pink2011]_8-0"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-[Pink2011]-8">[8]</a></sup> This leads to the following principle:

-   Systems tend to oppose their own proper function.<sup id="cite_ref-FOOTNOTEGall197848_9-0"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-FOOTNOTEGall197848-9">[9]</a></sup>

### What's in a name\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=10 "Edit section: What's in a name")\]

People performing roles in systems often do not perform the role suggested by the name the system gives that person, nor does the system itself perform the role that its name suggests.

-   People in systems do not actually do what the system says they are doing (Functionary's Falsity).<sup id="cite_ref-FOOTNOTEGall197858_10-0"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-FOOTNOTEGall197858-10">[10]</a></sup>
-   The system itself does not actually do what it says it is doing (The Operational Fallacy).

### Inside systems\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=11 "Edit section: Inside systems")\]

-   The real world is what is reported to the system (The Fundamental Law of Administrative Workings \[F.L.A.W.\]).<sup id="cite_ref-FOOTNOTEGall197865_11-0"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-FOOTNOTEGall197865-11">[11]</a></sup>

In other words, the system has a severely censored and distorted view of reality from biased and filtering sensory organs. This distorted view displaces understanding of the actual real-world, which in turn pales and tends to disappear. This displacement creates a type of sensory deprivation and a kind of hallucinogenic effect on those inside the systems, causing them to lose common sense. In addition to negatively affecting those inside the system, the system attracts to it people who are optimized for the pathological environment the system creates. Thus,

-   Systems attract systems-people.

### Elementary systems functions\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=12 "Edit section: Elementary systems functions")\]

1.  A complex system cannot be "made" to work. It either works or it does not.
2.  A simple system, designed from scratch, sometimes works.
3.  Some complex systems actually work.
4.  A complex system that works is invariably found to have evolved from a simple system that works.
5.  A complex system designed from scratch never works and cannot be patched up to make it work. One has to start over, beginning with a working simple system.<sup id="cite_ref-FOOTNOTEGall197879–82_12-0"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-FOOTNOTEGall197879%E2%80%9382-12">[12]</a></sup>

### Advanced systems functions\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=13 "Edit section: Advanced systems functions")\]

1.  The Functional Indeterminacy Theorem (F.I.T.): in complex systems, malfunction and even total non-function may not be detectable for long periods, if ever.
2.  The Newtonian Law of Systems Inertia: a system that performs a certain way will continue to operate in that way regardless of the need or of changed conditions.
3.  Systems develop goals of their own the instant they come into being.
4.  Intrasystem goals come first.<sup id="cite_ref-FOOTNOTEGall197883–90_13-0"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-FOOTNOTEGall197883%E2%80%9390-13">[13]</a></sup>

### System failure\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=14 "Edit section: System failure")\]

1.  The Fundamental Failure-Mode Theorem (F.F.T.): complex systems usually operate in a failure mode.
2.  A complex system can fail in an infinite number of ways. (If anything can go wrong, it will; see [Murphy's law](https://en.wikipedia.org/wiki/Murphy%27s_law "Murphy's law").)
3.  The mode of failure of a complex system cannot ordinarily be predicted from its structure.
4.  The crucial variables are discovered by accident.
5.  The larger the system, the greater the probability of unexpected failure.
6.  "Success" or "function" in any system may be failure in the larger or smaller systems to which the system is connected.
7.  The Fail-Safe Theorem: when a fail-safe system fails, it fails by failing to fail safe.<sup id="cite_ref-FOOTNOTEGall197891–97_14-0"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-FOOTNOTEGall197891%E2%80%9397-14">[14]</a></sup>

### Practical systems design\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=15 "Edit section: Practical systems design")\]

1.  The Vector Theory of Systems: systems run better when designed to run downhill.
2.  Loose systems last longer and work better. (Efficient systems are dangerous to themselves and to others.)<sup id="cite_ref-FOOTNOTEGall197899–104_15-0"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-FOOTNOTEGall197899%E2%80%93104-15">[15]</a></sup>

### Management and other myths\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=16 "Edit section: Management and other myths")\]

1.  Complex systems tend to produce complex responses (not solutions) to problems.
2.  Great advances are not produced by systems designed to produce great advances.<sup id="cite_ref-FOOTNOTEGall197899–110_16-0"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-FOOTNOTEGall197899%E2%80%93110-16">[16]</a></sup>

### Other laws of systemantics\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=17 "Edit section: Other laws of systemantics")\]

1.  As systems grow in size, they tend to lose basic functions.
2.  The larger the system, the less the variety in the product.
3.  Control of a system is exercised by the element with the greatest variety of behavioral responses.
4.  Colossal systems foster colossal errors.
5.  Choose systems with care.

## Reception\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=18 "Edit section: Reception")\]

_[Money](https://en.wikipedia.org/wiki/Money_(magazine) "Money (magazine)")_ stated in 1978 that the author "clearly set out to write another Peter Principle".<sup id="cite_ref-17"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-17">[17]</a></sup> A 1977 review in _[Etc: A Review of General Semantics](https://en.wikipedia.org/wiki/Etc:_A_Review_of_General_Semantics "Etc: A Review of General Semantics")_ states that the book's aim is unclear, commenting, "As a put-down of institutional practices it works well, as good as anything in print", but "As a slam at systems theory the book is less successful, even ambiguous."<sup id="cite_ref-18"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-18">[18]</a></sup> A _[Library Journal](https://en.wikipedia.org/wiki/Library_Journal "Library Journal")_ review from 1977 comments, "Like some of its predecessors, the book pretends to rebuke people for their manifold stupidities, but is, in fact, an invitation to take pleasure in them. That's not a failing, just a fact. Recommended."<sup id="cite_ref-19"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-19">[19]</a></sup> A 2004 review in the [American Society of Safety Professionals](https://en.wikipedia.org/wiki/American_Society_of_Safety_Professionals "American Society of Safety Professionals")' _Professional Safety_ says, "It is at once deadly serious with all the outrageous contrived irony of [Gary Larson](https://en.wikipedia.org/wiki/Gary_Larson "Gary Larson")'s '[Far Side](https://en.wikipedia.org/wiki/Far_Side "Far Side")' cartoons" and that "the book is one continuous insight after another."_<sup id="cite_ref-20"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-20">[20]</a></sup>_ _[PCMag](https://en.wikipedia.org/wiki/PCMag "PCMag")_ calls the book "small but insightful".<sup id="cite_ref-21"><a href="https://en.wikipedia.org/wiki/Systemantics#cite_note-21">[21]</a></sup>

## See also\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=19 "Edit section: See also")\]

-   [The purpose of a system is what it does](https://en.wikipedia.org/wiki/The_purpose_of_a_system_is_what_it_does "The purpose of a system is what it does")

## References\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=20 "Edit section: References")\]

1.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-1 "Jump up")** Serrin, Judith (1977-01-05). ["Why Things Just Won't Work"](https://www.newspapers.com/image/98263004/). _[Detroit Free Press](https://en.wikipedia.org/wiki/Detroit_Free_Press "Detroit Free Press")_. pp. 1C, 5C. Retrieved 2023-09-20 – via [Newspapers.com](https://en.wikipedia.org/wiki/Newspapers.com "Newspapers.com").
2.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-2 "Jump up")** Gall, John (1976-12-26). ["Why nothing works the way it's supposed to: Systemanantics"](https://www.proquest.com/docview/122788800). _[The New York Times](https://en.wikipedia.org/wiki/The_New_York_Times "The New York Times")_. pp. SM3. [ProQuest](https://en.wikipedia.org/wiki/ProQuest_(identifier) "ProQuest (identifier)") [122788800](https://search.proquest.com/docview/122788800). Retrieved 2024-01-12 – via [ProQuest](https://en.wikipedia.org/wiki/ProQuest "ProQuest").
3.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-FOOTNOTEGall197824_3-0 "Jump up")** [Gall 1978](https://en.wikipedia.org/wiki/Systemantics#CITEREFGall1978), p. 24.
4.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-FOOTNOTEGall197822_4-0 "Jump up")** [Gall 1978](https://en.wikipedia.org/wiki/Systemantics#CITEREFGall1978), p. 22.
5.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-FOOTNOTEGall197826_5-0 "Jump up")** [Gall 1978](https://en.wikipedia.org/wiki/Systemantics#CITEREFGall1978), p. 26.
6.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-FOOTNOTEGall197829_6-0 "Jump up")** [Gall 1978](https://en.wikipedia.org/wiki/Systemantics#CITEREFGall1978), p. 29.
7.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-FOOTNOTEGall197840_7-0 "Jump up")** [Gall 1978](https://en.wikipedia.org/wiki/Systemantics#CITEREFGall1978), p. 40.
8.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-[Pink2011]_8-0 "Jump up")** Pink, Daniel (2011). _Drive_. Penguin. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)") [978-1594484803](https://en.wikipedia.org/wiki/Special:BookSources/978-1594484803 "Special:BookSources/978-1594484803").
9.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-FOOTNOTEGall197848_9-0 "Jump up")** [Gall 1978](https://en.wikipedia.org/wiki/Systemantics#CITEREFGall1978), p. 48.
10.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-FOOTNOTEGall197858_10-0 "Jump up")** [Gall 1978](https://en.wikipedia.org/wiki/Systemantics#CITEREFGall1978), p. 58.
11.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-FOOTNOTEGall197865_11-0 "Jump up")** [Gall 1978](https://en.wikipedia.org/wiki/Systemantics#CITEREFGall1978), p. 65.
12.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-FOOTNOTEGall197879%E2%80%9382_12-0 "Jump up")** [Gall 1978](https://en.wikipedia.org/wiki/Systemantics#CITEREFGall1978), pp. 79–82.
13.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-FOOTNOTEGall197883%E2%80%9390_13-0 "Jump up")** [Gall 1978](https://en.wikipedia.org/wiki/Systemantics#CITEREFGall1978), pp. 83–90.
14.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-FOOTNOTEGall197891%E2%80%9397_14-0 "Jump up")** [Gall 1978](https://en.wikipedia.org/wiki/Systemantics#CITEREFGall1978), pp. 91–97.
15.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-FOOTNOTEGall197899%E2%80%93104_15-0 "Jump up")** [Gall 1978](https://en.wikipedia.org/wiki/Systemantics#CITEREFGall1978), pp. 99–104.
16.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-FOOTNOTEGall197899%E2%80%93110_16-0 "Jump up")** [Gall 1978](https://en.wikipedia.org/wiki/Systemantics#CITEREFGall1978), pp. 99–110.
17.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-17 "Jump up")** Harris, Marlys (January 1978). "Why Things Don't Work: Three books on systems". _[Money](https://en.wikipedia.org/wiki/Money_(magazine) "Money (magazine)")_. Vol. 7, no. 1.
18.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-18 "Jump up")** Quinby, David L. (December 1977). ["Review: General Sematics and General Systems: An Irreverent View"](https://www.jstor.org/stable/42575291). _[Etc: A Review of General Semantics](https://en.wikipedia.org/wiki/Etc:_A_Review_of_General_Semantics "Etc: A Review of General Semantics")_. **34** (4). [JSTOR](https://en.wikipedia.org/wiki/JSTOR_(identifier) "JSTOR (identifier)") [42575291](https://www.jstor.org/stable/42575291) – via JSTOR.
19.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-19 "Jump up")** Anderson, A. J. (1977-05-01). "Humor: Gall, John. Systemantics: How systems work and especially how they fail". _[Library Journal](https://en.wikipedia.org/wiki/Library_Journal "Library Journal")_. **102** (9): 1018 – via EBSCO.
20.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-20 "Jump up")** Metzgar, Carl R. (October 2004). ["Writing Worth Reading: Review: The Systems Bible"](https://www.jstor.org/stable/45453930). _Professional Safety_. **49** (10). [American Society of Safety Professionals](https://en.wikipedia.org/wiki/American_Society_of_Safety_Professionals "American Society of Safety Professionals"): 20, 72. [JSTOR](https://en.wikipedia.org/wiki/JSTOR_(identifier) "JSTOR (identifier)") [45453930](https://www.jstor.org/stable/45453930) – via JSTOR.
21.  **[^](https://en.wikipedia.org/wiki/Systemantics#cite_ref-21 "Jump up")** ["Definition of Systemantics"](https://www.pcmag.com/encyclopedia/term/systemantics). _[PCMag](https://en.wikipedia.org/wiki/PCMag "PCMag")_. Retrieved 2023-09-20.

## Sources\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=21 "Edit section: Sources")\]

-   Gall, John (2003). _The Systems Bible: The Beginner's Guide to Systems Large and Small_ (3rd ed.). Walker: General Systemantics Press. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)") [9780961825171](https://en.wikipedia.org/wiki/Special:BookSources/9780961825171 "Special:BookSources/9780961825171").
-   Gall, John (1986). _SYSTEMANTICS: The Underground Text of Systems Lore. How Systems Really Work and How They Fail_ (2nd ed.). Ann Arbor: General Systemantics Press. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)") [9780961825102](https://en.wikipedia.org/wiki/Special:BookSources/9780961825102 "Special:BookSources/9780961825102").
-   Gall, John (1978). _SYSTEMANTICS: How Systems Really Work and How They Fail_ (1st ed.). New York: Pocket Books. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)") [9780671819101](https://en.wikipedia.org/wiki/Special:BookSources/9780671819101 "Special:BookSources/9780671819101").

## External links\[[edit](https://en.wikipedia.org/w/index.php?title=Systemantics&action=edit&section=22 "Edit section: External links")\]

-   [Bart Stewart's Explanation of Systemantics](http://www.draftymanor.com/bart/systems1.htm)
-   [Commentary on the principles of "Systemantics", by Anthony Judge](https://www.laetusinpraesens.org/docs/systfail.php)
-   [c2 wiki entry on Systemantics](http://c2.com/cgi/wiki?GeneralSystemantics)
