---
source: en.m.wikipedia.org
url: https://en.m.wikipedia.org/wiki/Collective_action_problem
---

A **collective action problem** or **social dilemma** is a situation in which all individuals would be better off cooperating but fail to do so because of conflicting interests between individuals that discourage joint action.<sup id="cite_ref-1"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-1">[1]</a></sup><sup id="cite_ref-2"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-2">[2]</a></sup><sup id="cite_ref-3"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-3">[3]</a></sup> The [collective action](https://en.m.wikipedia.org/wiki/Collective_action "Collective action") problem has been addressed in [political philosophy](https://en.m.wikipedia.org/wiki/Political_philosophy "Political philosophy") for centuries, but was most clearly established in 1965 in [Mancur Olson's](https://en.m.wikipedia.org/wiki/Mancur_Olson "Mancur Olson") _[The Logic of Collective Action](https://en.m.wikipedia.org/wiki/The_Logic_of_Collective_Action "The Logic of Collective Action")_.

Problems arise when too many group members choose to pursue individual profit and immediate satisfaction rather than behave in the group's best long-term interests. Social dilemmas can take many forms and are studied across disciplines such as [psychology](https://en.m.wikipedia.org/wiki/Psychology "Psychology"), [economics](https://en.m.wikipedia.org/wiki/Economics "Economics"), and [political science](https://en.m.wikipedia.org/wiki/Political_science "Political science"). Examples of phenomena that can be explained using social dilemmas include [resource depletion](https://en.m.wikipedia.org/wiki/Resource_depletion "Resource depletion") and low [voter turnout](https://en.m.wikipedia.org/wiki/Voter_turnout "Voter turnout"). The collective action problem can be understood through the analysis of [game theory](https://en.m.wikipedia.org/wiki/Game_theory "Game theory") and the [free-rider problem](https://en.m.wikipedia.org/wiki/Free-rider_problem "Free-rider problem"), which results from the provision of [public goods](https://en.m.wikipedia.org/wiki/Public_good_(economics) "Public good (economics)"). Additionally, the collective problem can be applied to numerous public policy concerns that countries across the world currently face.

## Prominent theorists [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=1 "Edit section: Prominent theorists")

### Early thought [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=2 "Edit section: Early thought")

Although he never used the words "collective action problem", [Thomas Hobbes](https://en.m.wikipedia.org/wiki/Thomas_Hobbes "Thomas Hobbes") was an early philosopher on the topic of human cooperation. Hobbes believed that people act purely out of self-interest, writing in [_Leviathan_](https://en.m.wikipedia.org/wiki/Leviathan_(Hobbes_book) "Leviathan (Hobbes book)") in 1651 that "if any two men desire the same thing, which nevertheless they cannot both enjoy, they become enemies."<sup id="cite_ref-4"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-4">[4]</a></sup> Hobbes believed that the [state of nature](https://en.m.wikipedia.org/wiki/State_of_nature "State of nature") consists of a perpetual war between people with conflicting interests, causing people to quarrel and seek personal power even in situations where cooperation would be mutually beneficial for both parties. Through his interpretation of humans in the state of nature as selfish and quick to engage in conflict, Hobbes's philosophy laid the foundation for what is now referred to as the collective action problem.

[David Hume](https://en.m.wikipedia.org/wiki/David_Hume "David Hume") provided another early and better-known interpretation of what is now called the collective action problem in his 1738 book _[A Treatise of Human Nature](https://en.m.wikipedia.org/wiki/A_Treatise_of_Human_Nature "A Treatise of Human Nature")_. Hume characterizes a collective action problem through his depiction of neighbors agreeing to drain a meadow:

> Two neighbours may agree to drain a meadow, which they possess in common; because it is easy for them to know each others mind; and each must perceive, that the immediate consequence of his failing in his part, is, the abandoning the whole project. But it is very difficult, and indeed impossible, that a thousand persons should agree in any such action; it being difficult for them to concert so complicated a design, and still more difficult for them to execute it; while each seeks a pretext to free himself of the trouble and expence, and would lay the whole burden on others.<sup id="cite_ref-5"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-5">[5]</a></sup>

In this passage, Hume establishes the basis for the collective action problem. In a situation in which a thousand people are expected to work together to achieve a common goal, individuals will be likely to [free ride](https://en.m.wikipedia.org/wiki/Free-rider_problem "Free-rider problem"), as they assume that each of the other members of the team will put in enough effort to achieve said goal. In smaller groups, the impact one individual has is much greater, so individuals will be less inclined to free ride.

### Modern thought [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=3 "Edit section: Modern thought")

The most prominent modern interpretation of the collective action problem can be found in [Mancur Olson's](https://en.m.wikipedia.org/wiki/Mancur_Olson "Mancur Olson") 1965 book _[The Logic of Collective Action](https://en.m.wikipedia.org/wiki/The_Logic_of_Collective_Action "The Logic of Collective Action")_.<sup id="cite_ref-:02_6-0"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-:02-6">[6]</a></sup> In it, he addressed the accepted belief at the time by sociologists and political scientists that groups were necessary to further the interests of their members. Olson argued that individual rationality does not necessarily result in group rationality, as members of a group may have conflicting interests that do not represent the best interests of the overall group.

Olson further argued that in the case of a pure [public good](https://en.m.wikipedia.org/wiki/Public_good_(economics) "Public good (economics)") that is both nonrival and nonexcludable, one contributor tends to reduce their contribution to the public good as others contribute more. Additionally, Olson emphasized the tendency of individuals to pursue economic interests that would be beneficial to themselves and not necessarily the overall public. This contrasts with [Adam Smith's](https://en.m.wikipedia.org/wiki/Adam_Smith "Adam Smith") theory of the "[invisible hand](https://en.m.wikipedia.org/wiki/Invisible_hand "Invisible hand")" of the market, where individuals pursuing their own interests should theoretically result in the collective well-being of the overall market.<sup id="cite_ref-:02_6-1"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-:02-6">[6]</a></sup>

Olson's book established the collective action problem as one of the most troubling dilemmas in social science, leaving a profound impression on present-day discussions of human behavior and its relationship with governmental policy.

## Theories [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=4 "Edit section: Theories")

### Game theory [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=5 "Edit section: Game theory")

 [](https://en.m.wikipedia.org/wiki/File:Prisoner%27s_Dilemma.jpg)

This chart illustrates the prisoner's dilemma, one of the most famous examples of game theory.

Social dilemmas have attracted a great deal of interest in the social and behavioral sciences. Economists, biologists, psychologists, sociologists, and political scientists alike study behavior in social dilemmas. The most influential theoretical approach is economic game theory (i.e., rational choice theory, expected utility theory). Game theory assumes that individuals are rational actors motivated to maximize their utilities. Utility is often narrowly defined in terms of people's economic self-interest. Game theory thus predicts a non-cooperative outcome in a social dilemma. Although this is a useful starting premise there are many circumstances in which people may deviate from individual rationality.<sup id="cite_ref-7"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-7">[7]</a></sup>

[Game theory](https://en.m.wikipedia.org/wiki/Game_theory "Game theory") is one of the principal components of economic theory. It addresses the way individuals allocate scarce resources and how scarcity drives human interaction.<sup id="cite_ref-8"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-8">[8]</a></sup> One of the most famous examples of game theory is the [prisoner's dilemma](https://en.m.wikipedia.org/wiki/Prisoner%27s_dilemma "Prisoner's dilemma"). The classical prisoner's dilemma model consists of two players who are accused of a crime. If Player A decides to betray Player B, Player A will receive no prison time while Player B receives a substantial prison sentence, and vice versa. If both players choose to keep quiet about the crime, they will both receive reduced prison sentences, and if both players turn the other in, they will each receive more substantial sentences. It would appear in this situation that each player should choose to stay quiet so that both will receive reduced sentences. In actuality, however, players who are unable to communicate will both choose to betray each other, as they each have an individual incentive to do so in order to receive a commuted sentence.<sup id="cite_ref-9"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-9">[9]</a></sup>

#### Prisoner's dilemma [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=6 "Edit section: Prisoner's dilemma")

The prisoner's dilemma model is crucial to understanding the collective problem because it illustrates the consequences of individual interests that conflict with the interests of the group. In simple models such as this one, the problem would have been solved had the two prisoners been able to communicate. In more complex real world situations involving numerous individuals, however, the collective action problem often prevents groups from making decisions that are of collective economic interest.<sup id="cite_ref-10"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-10">[10]</a></sup>

The [prisoner's dilemma](https://en.m.wikipedia.org/wiki/Prisoner%27s_dilemma "Prisoner's dilemma") is a simple game<sup id="cite_ref-11"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-11">[11]</a></sup> that serves as the basis for research on social dilemmas.<sup id="cite_ref-12"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-12">[12]</a></sup> The premise of the game is that two partners in crime are imprisoned separately and each are offered leniency if they provide evidence against the other. As seen in the table below, the optimal individual outcome is to testify against the other without being testified against. However, the optimal group outcome is for the two prisoners to cooperate with each other.

|  | Prisoner B does not confess (_cooperates_) | Prisoner B confesses (_defects_) |
| --- | --- | --- |
| Prisoner A does not confess (_cooperates_) | Each serves 1 year | Prisoner A: 3 years  
Prisoner B: goes free |
| Prisoner A confesses (_defects_) | Prisoner A: goes free  
Prisoner B: 3 years | Each serves 2 years |

In iterated games, players may learn to trust one another, or develop strategies like tit-for-tat, cooperating unless the opponent has defected in the previous round.

Asymmetric prisoner's dilemma games are those in which one prisoner has more to gain and/or lose than the other.<sup id="cite_ref-13"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-13">[13]</a></sup> In iterated experiments with unequal rewards for co-operation, a goal of maximizing benefit may be overruled by a goal of equalizing benefit. The disadvantaged player may defect a certain proportion of the time without it being in the interest of the advantaged player to defect.<sup id="cite_ref-14"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-14">[14]</a></sup> In more natural circumstances, there may be better solutions to the [bargaining problem](https://en.m.wikipedia.org/wiki/Bargaining_problem "Bargaining problem").

Related games include the [Snowdrift game](https://en.m.wikipedia.org/wiki/Snowdrift_game "Snowdrift game"), [Stag hunt](https://en.m.wikipedia.org/wiki/Stag_hunt "Stag hunt"), the [Unscrupulous diner's dilemma](https://en.m.wikipedia.org/wiki/Unscrupulous_diner%27s_dilemma "Unscrupulous diner's dilemma"), and the [Centipede game](https://en.m.wikipedia.org/wiki/Centipede_game "Centipede game").

### Evolutionary theories [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=7 "Edit section: Evolutionary theories")

Biological and evolutionary approaches provide useful complementary insights into decision-making in social dilemmas. According to [selfish gene](https://en.m.wikipedia.org/wiki/Gene-centered_view_of_evolution "Gene-centered view of evolution") theory, individuals may pursue a seemingly irrational strategy to cooperate if it benefits the survival of their genes. The concept of [inclusive fitness](https://en.m.wikipedia.org/wiki/Inclusive_fitness "Inclusive fitness") delineates that cooperating with family members might pay because of shared genetic interests. It might be profitable for a parent to help their off-spring because doing so facilitates the survival of their genes. Reciprocity theories provide a different account of the evolution of cooperation. In repeated social dilemma games between the same individuals, cooperation might emerge because participants can punish a partner for failing to cooperate. This encourages reciprocal cooperation. [Reciprocity](https://en.m.wikipedia.org/wiki/Reciprocity_(social_and_political_philosophy) "Reciprocity (social and political philosophy)") serves as an explanation for why participants cooperate in [dyads](https://en.m.wikipedia.org/wiki/Dyad_(sociology) "Dyad (sociology)"), but fails to account for larger groups. Evolutionary theories of indirect reciprocity and costly signaling may be useful to explain large-scale cooperation. When people can selectively choose partners to play games with, it pays to develop a cooperative [reputation](https://en.m.wikipedia.org/wiki/Reputation "Reputation"). Cooperation communicates kindness and generosity, which combine to make someone an attractive group member.

### Psychological theories [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=8 "Edit section: Psychological theories")

Psychological models offer additional insights into social dilemmas by questioning the game theory assumption that individuals are confined to their narrow self-interest. [Interdependence Theory](https://en.m.wikipedia.org/wiki/Interdependence_Theory "Interdependence Theory") suggests that people transform a given pay-off matrix into an effective matrix that is more consistent with their social dilemma preferences. A prisoner's dilemma with close kin, for example, changes the pay-off matrix into one in which it is rational to be cooperative. Attribution models offer further support for these transformations. Whether individuals approach a social dilemma selfishly or cooperatively might depend upon whether they believe people are naturally greedy or cooperative. Similarly, [goal-expectation theory](https://en.m.wikipedia.org/w/index.php?title=Goal-expectation_theory&action=edit&redlink=1 "Goal-expectation theory (page does not exist)") assumes that people might cooperate under two conditions: They must (1) have a cooperative goal, and (2) expect others to cooperate. Another psychological model, the appropriateness model, questions the game theory assumption that individuals rationally calculate their pay-offs. Instead many people base their decisions on what people around them do and use simple [heuristics](https://en.m.wikipedia.org/wiki/Heuristics "Heuristics"), like an equality rule, to decide whether or not to cooperate. The logic of appropriateness suggests that people ask themselves the question: "what does a person like me (identity) do (rules/heuristics) in a situation like this (recognition) given this culture (group)?" (Weber _et al._, 2004) <sup id="cite_ref-15"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-15">[15]</a></sup> (Kopelman 2009)<sup id="cite_ref-16"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-16">[16]</a></sup> and that these factors influence cooperation.

## Public goods [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=9 "Edit section: Public goods")

A [public goods](https://en.m.wikipedia.org/wiki/Public_goods "Public goods") dilemma is a situation in which the whole group can benefit if some of the members give something for the common good but individuals benefit from “free riding” if enough others contribute.<sup id="cite_ref-17"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-17">[17]</a></sup> Public goods are defined by two characteristics: non-excludability and non-rivalry—meaning that anyone can benefit from them and one person's use of them does not hinder another person's use of them. An example is public broadcasting that relies on contributions from viewers. Since no single viewer is essential for providing the service, viewers can reap the benefits of the service without paying anything for it. If not enough people contribute, the service cannot be provided. In economics, the literature around public goods dilemmas refers to the phenomenon as the free rider problem. The economic approach is broadly applicable and can refer to the free-riding that accompanies any sort of public good.<sup id="cite_ref-18"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-18">[18]</a></sup> In social psychology, the literature refers to this phenomenon as social loafing. Whereas free-riding is generally used to describe public goods, social loafing refers specifically to the tendency for people to exert less effort when in a group than when working alone.<sup id="cite_ref-19"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-19">[19]</a></sup>

Public goods are goods that are [nonrival](https://en.m.wikipedia.org/wiki/Rivalry_(economics) "Rivalry (economics)") and [nonexcludable](https://en.m.wikipedia.org/wiki/Excludability "Excludability"). A good is said to be nonrival if its consumption by one consumer does not in any way impact its consumption by another consumer. Additionally, a good is said to be nonexcludable if those who do not pay for the good cannot be kept from enjoying the benefits of the good.<sup id="cite_ref-:12_20-0"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-:12-20">[20]</a></sup> The nonexcludability aspect of public goods is where one facet of the collective action problem, known as the [free-rider problem](https://en.m.wikipedia.org/wiki/Free-rider_problem "Free-rider problem"), comes into play. For instance, a company could put on a fireworks display and charge an admittance price of $10, but if community members could all view the fireworks display from their homes, most would choose not to pay the admittance fee. Thus, the majority of individuals would choose to free ride, discouraging the company from putting on another fireworks show in the future. Even though the fireworks display was surely beneficial to each of the individuals, they relied on those paying the admittance fee to finance the show. If everybody had assumed this position, however, the company putting on the show would not have been able to procure the funds necessary to buy the fireworks that provided enjoyment for so many individuals. This situation is indicative of a collective action problem because the individual incentive to free ride conflicts with the collective desire of the group to pay for a fireworks show for all to enjoy.<sup id="cite_ref-:12_20-1"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-:12-20">[20]</a></sup>

Pure public goods include services such as [national defense](https://en.m.wikipedia.org/wiki/National_defense "National defense") and public parks that are usually provided by governments using taxpayer funds.<sup id="cite_ref-:12_20-2"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-:12-20">[20]</a></sup> In return for their tax contribution, taxpayers enjoy the benefits of these public goods. In developing countries where funding for public projects is scarce, however, it often falls on communities to compete for resources and finance projects that benefit the collective group.<sup id="cite_ref-:22_21-0"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-:22-21">[21]</a></sup> The ability of communities to successfully contribute to public welfare depends on the size of the group, the power or influence of group members, the tastes and preferences of individuals within the group, and the distribution of benefits among group members. When a group is too large or the benefits of collective action are not tangible to individual members, the collective action problem results in a lack of cooperation that makes the provision of public goods difficult.<sup id="cite_ref-:22_21-1"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-:22-21">[21]</a></sup>

## Replenishing resource management [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=10 "Edit section: Replenishing resource management")

A replenishing resource management dilemma is a situation in which group members share a renewable resource that will continue to produce benefits if group members do not over harvest it but in which any single individual profits from harvesting as much as possible.<sup id="cite_ref-22"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-22">[22]</a></sup>

### Tragedy of the commons [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=11 "Edit section: Tragedy of the commons")

 [](https://en.m.wikipedia.org/wiki/File:Surexploitation_morue_surp%C3%AAcheEn.jpg)

[Atlantic cod](https://en.m.wikipedia.org/wiki/Atlantic_cod "Atlantic cod") stocks were severely overexploited in the 1970s and 1980s, leading to their abrupt collapse in 1992.<sup id="cite_ref-Frank_23-0"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-Frank-23">[23]</a></sup>

The [tragedy of the commons](https://en.m.wikipedia.org/wiki/Tragedy_of_the_commons "Tragedy of the commons") is a type of replenishing resource management dilemma. The dilemma arises when members of a group share a [common good](https://en.m.wikipedia.org/wiki/Common_good_(economics) "Common good (economics)"). A common good is rivalrous and non-excludable, meaning that anyone can use the resource but there is a finite amount of the resource available and it is therefore prone to [overexploitation](https://en.m.wikipedia.org/wiki/Overexploitation "Overexploitation").<sup id="cite_ref-24"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-24">[24]</a></sup>

The paradigm of the tragedy of the commons first appeared in an 1833 pamphlet by English economist [William Forster Lloyd](https://en.m.wikipedia.org/wiki/William_Forster_Lloyd "William Forster Lloyd"). According to Lloyd, "If a person puts more cattle into his own field, the amount of the subsistence which they consume is all deducted from that which was at the command, of his original stock; and if, before, there was no more than a sufficiency of pasture, he reaps no benefit from the additional cattle, what is gained in one way being lost in another. But if he puts more cattle on a common, the food which they consume forms a deduction which is shared between all the cattle, as well that of others as his own, in proportion to their number, and only a small part of it is taken from his own cattle".<sup id="cite_ref-25"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-25">[25]</a></sup>

The template of the tragedy of the commons can be used to understand myriad problems, including various forms of [resource depletion](https://en.m.wikipedia.org/wiki/Resource_depletion "Resource depletion"). For example, overfishing in the 1960s and 1970s led to depletion of the previously abundant supply of [Atlantic Cod](https://en.m.wikipedia.org/wiki/Atlantic_Cod "Atlantic Cod"). By 1992, the population of cod had completely collapsed because fishers had not left enough fish to repopulate the species.<sup id="cite_ref-Frank_23-1"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-Frank-23">[23]</a></sup> Another example is the higher rates of COVID-19 cases of sickness and deaths in individualistic (vs. collectivists) countries.<sup id="cite_ref-26"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-26">[26]</a></sup>

## [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=12 "Edit section: Social traps")

 [](https://en.m.wikipedia.org/wiki/File:Smoke_Above_Sintagma.jpg)

Pollution in the sky of [Athens](https://en.m.wikipedia.org/wiki/Athens "Athens"), [Greece](https://en.m.wikipedia.org/wiki/Greece "Greece").

A [social trap](https://en.m.wikipedia.org/wiki/Social_trap "Social trap") occurs when individuals or groups pursue immediate rewards that later prove to have negative or even lethal consequences.<sup id="cite_ref-27"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-27">[27]</a></sup> This type of dilemma arises when a behavior produces rewards initially but continuing the same behavior produces [diminishing returns](https://en.m.wikipedia.org/wiki/Diminishing_returns "Diminishing returns"). Stimuli that cause social traps are called sliding reinforcers, since they reinforce the behavior in small doses and punish it in large doses.

An example of a social trap is the use of vehicles and the resulting pollution. Viewed individually, vehicles are an adaptive technology that have revolutionized transportation and greatly improved quality of life. But their current widespread use produces high levels of pollution, directly from their energy source or over their lifespan.

## Perceptual dilemma [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=13 "Edit section: Perceptual dilemma")

A perceptual dilemma arises during conflict and is a product of outgroup bias. In this dilemma, the parties to the conflict prefer cooperation while simultaneously believing that the other side would take advantage of conciliatory gestures.<sup id="cite_ref-28"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-28">[28]</a></sup>

### In conflict [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=14 "Edit section: In conflict")

The prevalence of perceptual dilemmas in conflict has led to the development of two distinct schools of thought on the subject. According to [deterrence theory](https://en.m.wikipedia.org/wiki/Deterrence_theory "Deterrence theory"), the best strategy to take in conflict is to show signs of strength and willingness to use force if necessary. This approach is intended to dissuade attacks before they happen. Conversely, the conflict spiral view holds that deterrence strategies increase hostilities and defensiveness and that a clear demonstration of peaceful intentions is the most effective way to avoid escalation.<sup id="cite_ref-29"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-29">[29]</a></sup>

An example of the deterrence theory in practice is the [Cold War](https://en.m.wikipedia.org/wiki/Cold_War "Cold War") strategy (employed by both the United States and the [Soviet Union](https://en.m.wikipedia.org/wiki/Soviet_Union "Soviet Union")) of [mutually assured destruction](https://en.m.wikipedia.org/wiki/Mutually_assured_destruction "Mutually assured destruction") (MAD). Because both countries had [second strike capability](https://en.m.wikipedia.org/wiki/Second_strike_capability "Second strike capability"), each side knew that the use of nuclear weapons would result in their own destruction. While controversial, MAD succeeded in its primary purpose of preventing nuclear war and kept the Cold War cold.

Conciliatory gestures have also been used to great effect, in keeping with conflict spiral theory. For example, [Egyptian President](https://en.m.wikipedia.org/wiki/Egyptian_President "Egyptian President") [Anwar El Sadat](https://en.m.wikipedia.org/wiki/Anwar_El_Sadat "Anwar El Sadat")'s 1977 visit to [Israel](https://en.m.wikipedia.org/wiki/Israel "Israel") during a prolonged period of hostilities between the two countries was well-received and ultimately contributed in the [Egypt–Israel peace treaty](https://en.m.wikipedia.org/wiki/Egypt%E2%80%93Israel_peace_treaty "Egypt–Israel peace treaty").

## In politics [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=15 "Edit section: In politics")

### Voting [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=16 "Edit section: Voting")

Scholars estimate that, even in a battleground state, there is only a one in ten million chance that one vote could sway the outcome of a [United States presidential election](https://en.m.wikipedia.org/wiki/United_States_presidential_election "United States presidential election").<sup id="cite_ref-30"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-30">[30]</a></sup> This statistic may discourage individuals from exercising their democratic right to vote, as they believe they could not possibly affect the results of an election. If everybody adopted this view and decided not to vote, however, democracy would collapse. This situation results in a collective action problem, as any single individual is incentivized to choose to stay home from the polls since their vote is very unlikely to make a real difference in the outcome of an election.

Despite high levels of [political apathy](https://en.m.wikipedia.org/wiki/Political_apathy "Political apathy") in the United States, however, this collective action problem does not decrease voter turnout as much as some political scientists might expect.<sup id="cite_ref-31"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-31">[31]</a></sup> It turns out that most Americans believe their [political efficacy](https://en.m.wikipedia.org/wiki/Political_efficacy "Political efficacy") to be higher than it actually is, stopping millions of Americans from believing their vote does not matter and staying home from the polls. Thus, it appears collective action problems can be resolved not just by tangible benefits to individuals participating in group action, but by a mere belief that collective action will also lead to individual benefits.

### Environmental policy [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=17 "Edit section: Environmental policy")

Environmental problems such as [climate change](https://en.m.wikipedia.org/wiki/Climate_change "Climate change"), [biodiversity loss](https://en.m.wikipedia.org/wiki/Biodiversity_loss "Biodiversity loss"), and waste accumulation can be described as collective action problems.<sup id="cite_ref-:32_32-0"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-:32-32">[32]</a></sup> Since these issues are connected to the everyday actions of vast numbers of people, vast numbers of people are also required to mitigate the effects of these environmental problems. Without governmental regulation, however, individual people or businesses are unlikely to take the actions necessary to reduce [carbon emissions](https://en.m.wikipedia.org/wiki/Carbon_emission "Carbon emission") or cut back on usage of [non-renewable resources](https://en.m.wikipedia.org/wiki/Non-renewable_resource "Non-renewable resource"), as these people and businesses are incentivized to choose the easier and cheaper option, which often differs from the environmentally-friendly option that would benefit the health of the planet.<sup id="cite_ref-:32_32-1"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-:32-32">[32]</a></sup>

Individual self interest has led to over half of Americans believing that government regulation of businesses does more harm than good. Yet, when the same Americans are asked about specific regulations such as standards for food and water quality, most are satisfied with the laws currently in place or favor even more stringent regulations.<sup id="cite_ref-33"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-33">[33]</a></sup> This illustrates the way the collective problem hinders group action on environmental issues: when an individual is directly affected by an issue such as food and water quality, they will favor regulations, but when an individual cannot see a great impact from their personal carbon emissions or waste accumulation, they will generally tend to disagree with laws that encourage them to cut back on environmentally-harmful activities.

## [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=18 "Edit section: Factors promoting cooperation in social dilemmas")

Studying the conditions under which people cooperate can shed light on how to resolve social dilemmas. The literature distinguishes between three broad classes of solutions—motivational, strategic, and structural—which vary in whether they see actors as motivated purely by self-interest and in whether they change the rules of the social dilemma game.

### Motivational solutions [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=19 "Edit section: Motivational solutions")

Motivational solutions assume that people have other-regarding preferences. There is a considerable literature on [social value orientations](https://en.m.wikipedia.org/wiki/Social_value_orientations "Social value orientations") which shows that people have stable preferences for how much they value outcomes for self versus others. Research has concentrated on three social motives: (1) individualism—maximizing own outcomes regardless of others; (2) competition—maximizing own outcomes relative to others; and (3) cooperation—maximizing joint outcomes. The first two orientations are referred to as proself orientations and the third as a prosocial orientation. There is much support for the idea that prosocial and proself individuals behave differently when confronted with a social dilemma in the laboratory as well as the field.<sup>[<i><a href="https://en.m.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (August 2008)">citation needed</span></a></i>]</sup> People with prosocial orientations weigh the moral implications of their decisions more and see cooperation as the most preferable choice in a social dilemma. When there are conditions of scarcity, like a water shortage, prosocials harvest less from a common resource. Similarly prosocials are more concerned about the environmental consequences of, for example, taking the car or public transport.<sup id="cite_ref-34"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-34">[34]</a></sup>

Research on the development of social value orientations suggest an influence of factors like family history (prosocials have more sibling sisters), age (older people are more prosocial), culture (more individualists in Western cultures), gender (more women are prosocial), even university course (economics students are less prosocial). However, until we know more about the psychological mechanisms underlying these social value orientations we lack a good basis for interventions.

Another factor that might affect the weight individuals assign to group outcomes is the possibility of [communication](https://en.m.wikipedia.org/wiki/Communication "Communication"). A robust finding in the social dilemma literature is that cooperation increases when people are given a chance to talk to each other. It has been quite a challenge to explain this effect. One motivational reason is that communication reinforces a sense of group identity.<sup id="cite_ref-35"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-35">[35]</a></sup>

However, there may be strategic considerations as well. First, communication gives group members a chance to make promises and explicit commitments about what they will do. It is not clear if many people stick to their promises to cooperate. Similarly, through communication people are able to gather information about what others do. On the other hand, this information might produce ambiguous results; an awareness of other people's willingness to cooperate may cause a temptation to take advantage of them.

Social dilemma theory was applied to study social media communication and knowledge sharing in organizations. Organizational knowledge can be considered a public good where motivation to contribute is key. Both intrinsic and extrinsic motivation are important at individual level and can be addressed through managerial interventions.<sup id="cite_ref-36"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-36">[36]</a></sup>

### Strategic solutions [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=20 "Edit section: Strategic solutions")

A second category of solutions are primarily strategic. In repeated interactions cooperation might emerge when people adopt a [Tit for tat](https://en.m.wikipedia.org/wiki/Tit_for_tat "Tit for tat") strategy (TFT). TFT is characterized by first making a cooperative move while the next move mimics the decision of the partner. Thus, if a partner does not cooperate, you copy this move until your partner starts to cooperate. Computer tournaments in which different strategies were pitted against each other showed TFT to be the most successful strategy in social dilemmas. TFT is a common strategy in real-world social dilemmas because it is nice but firm. Consider, for instance, that marriage contracts, rental agreements, and international trade policies all use TFT-tactics.

However, TFT is quite an unforgiving strategy, and in noisy real-world dilemmas a more forgiving strategy has its own advantages. Such a strategy is known as Generous-tit-for-tat (GTFT).<sup id="cite_ref-Nowak_&amp;_Sigmund,_1992_37-0"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-Nowak_&amp;_Sigmund,_1992-37">[37]</a></sup> This strategy always reciprocates cooperation with cooperation, and usually replies to defection with defection. However, with some probability GTFT will forgive a defection by the other player and cooperate. In a world of errors in action and perception, such a strategy can be a [Nash equilibrium](https://en.m.wikipedia.org/wiki/Nash_equilibrium "Nash equilibrium") and evolutionarily stable. The more beneficial cooperation is, the more forgiving GTFT can be while still resisting invasion by defectors.

Even when partners might not meet again it could be strategically wise to cooperate. When people can selectively choose whom to interact with it might pay to be seen as a cooperator. Research shows that cooperators create better opportunities for themselves than non-cooperators: They are selectively preferred as collaborative partners, romantic partners, and group leaders. This only occurs however when people's social dilemma choices are monitored by others. Public acts of altruism and cooperation like charity giving, philanthropy, and bystander intervention are probably manifestations of reputation-based cooperation.

### Structural solutions [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=21 "Edit section: Structural solutions")

Structural solutions change the rules of the game either through modifying the social dilemma or removing the dilemma altogether. Field research on conservation behaviour has shown that selective incentives in the form of monetary rewards are effective in decreasing domestic water and electricity use.<sup>[<i><a href="https://en.m.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (August 2008)">citation needed</span></a></i>]</sup> Furthermore, numerous experimental and case studies show that [cooperation](https://en.m.wikipedia.org/wiki/Cooperation "Cooperation") is more likely based on a number of factors, including whether or not individuals have the ability to monitor the situation, to punish or "sanction" defectors, if they are legitimized by external political structures to cooperate and self-organize, can communicate with one another and share information, know one another, have effective arenas for conflict resolution, and are managing social and ecological systems that have well-defined boundaries or are easily monitorable.<sup id="cite_ref-38"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-38">[38]</a></sup><sup id="cite_ref-39"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-39">[39]</a></sup> Yet implementation of reward and punishment systems can be problematic for various reasons. First, there are significant costs associated with creating and administering sanction systems. Providing selective rewards and punishments requires support institutions to monitor the activities of both cooperators and non-cooperators, which can be quite expensive to maintain. Second, these systems are themselves [public goods](https://en.m.wikipedia.org/wiki/Public_goods "Public goods") because one can enjoy the benefits of a sanctioning system without contribution to its existence. The police, army, and judicial system will fail to operate unless people are willing to pay taxes to support them. This raises the question if many people want to contribute to these institutions. Experimental research suggests that particularly low trust individuals are willing to invest money in punishment systems.<sup id="cite_ref-40"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-40">[40]</a></sup> A considerable portion of people are quite willing to punish non-cooperators even if they personally do not profit. Some researchers even suggest that altruistic punishment is an evolved mechanism for human cooperation. A third limitation is that punishment and reward systems might undermine people's voluntary cooperative intention. Some people get a "warm glow" from cooperation and the provision of selective incentives might crowd out their cooperative intention. Similarly the presence of a negative [sanctioning](https://en.m.wikipedia.org/wiki/Negative_reinforcement "Negative reinforcement") system might undermine voluntary cooperation. Some research has found that punishment systems decrease the trust that people have in others.<sup id="cite_ref-41"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-41">[41]</a></sup> Other research has found that _graduated_ sanctions, where initial punishments have low severity, make allowances for unusual hardships, and allow the violator to reenter the trust of the collective, have been found to support collective resource management and increase trust in the system.<sup id="cite_ref-42"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-42">[42]</a></sup><sup id="cite_ref-43"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-43">[43]</a></sup>

Boundary structural solutions modify the social dilemma structure and such strategies are often very effective. Experimental studies on commons dilemmas show that [overharvesting](https://en.m.wikipedia.org/wiki/Overharvesting "Overharvesting") groups are more willing to appoint a leader to look after the common resource. There is a preference for a democratically elected prototypical [leader](https://en.m.wikipedia.org/wiki/Leader "Leader") with limited power especially when people's group ties are strong.<sup id="cite_ref-44"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-44">[44]</a></sup> When ties are weak, groups prefer a stronger leader with a coercive power base. The question remains whether authorities can be trusted in governing social dilemmas and field research shows that legitimacy and fair procedures are extremely important in citizen's willingness to accept authorities. Other research emphasizes a greater motivation for groups to successfully self-organize, without the need for an external authority base, when they do place a high value on the resources in question but, again, before the resources are severely overharvested. An external "authority" is not presumed to be the solution in these cases, however effective self-organization and collective governance and care for the resource base is.<sup id="cite_ref-Ostrom_2009_419–422_45-0"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-Ostrom_2009_419%E2%80%93422-45">[45]</a></sup>

Another structural solution is reducing group size. Cooperation generally declines when group size increases. In larger groups people often feel less responsible for the common good and believe that their contribution does not matter. Reducing the scale of a problem (such as dividing a large scale dilemma into smaller more manageable parts) is often an effective tool in raising cooperation under such circumstances. Additional research on governance shows that group size has a curvilinear effect, since at low numbers, governance groups may also not have enough people to effectively research, manage, and administer the resource system or the governance process.<sup id="cite_ref-Ostrom_2009_419–422_45-1"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-Ostrom_2009_419%E2%80%93422-45">[45]</a></sup>

Another proposed boundary solution is to remove the social from the dilemma, by means of [privatization](https://en.m.wikipedia.org/wiki/Privatization "Privatization"). This restructuring of incentives would remove the temptation to place individual needs above group needs. However, it is not easy to privatize moveable resources such as fish, water, and clean air. Privatization also raises concerns about social justice as not everyone may be able to get an equal share. Privatization might also erode people's intrinsic motivation to cooperate, by externalizing the [locus of control](https://en.m.wikipedia.org/wiki/Locus_of_control "Locus of control").

In society, social units which face a social dilemma within are typically embedded in interaction with other groups, often competition for resources of different kinds. Once this is modeled the social dilemma is strongly attenuated.<sup id="cite_ref-46"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-46">[46]</a></sup>

There are many additional structural solutions which modify the social dilemma, both from the inside and from the outside. The likelihood of successfully co-managing a shared resource, successfully organizing to self-govern, or successfully cooperating in a social dilemma depends on many variables, from the nature of the resource system, to the nature of the social system the actors are a part of, to the political position of external authorities, to the ability to communicate effectively, to the rules-in-place regarding the management of the commons.<sup id="cite_ref-47"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-47">[47]</a></sup> However, _sub-optimal_ or _failed_ results in a social dilemma (and perhaps the need for privatization or an external authority) tend to occur "when resource users do _not_ know who all is involved, do not have a foundation of trust and reciprocity, cannot communicate, have no established rules, and lack effective monitoring and sanctioning mechanisms."<sup id="cite_ref-48"><a href="https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_note-48">[48]</a></sup>

## Conclusions [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=22 "Edit section: Conclusions")

Close examination reveals that social dilemmas underlie many of the most pressing global issues, from [climate change](https://en.m.wikipedia.org/wiki/Climate_change "Climate change") to [conflict escalation](https://en.m.wikipedia.org/wiki/Conflict_escalation "Conflict escalation"). Their widespread importance warrants widespread understanding of the main types of dilemmas and accompanying paradigms. Fortunately, the literature on the subject is expanding to accommodate the pressing need to understand social dilemmas as the basis for real-world problems.

Research in this area is applied to areas such as organizational welfare, public health, local and global environmental change. The emphasis is shifting from pure laboratory research towards research testing combinations of motivational, strategic, and structural solutions. It is encouraging that researchers from various behavioral sciences are developing unifying theoretical frameworks to study social dilemmas (like evolutionary theory; or the Social-Ecological Systems framework developed by [Elinor Ostrom](https://en.m.wikipedia.org/wiki/Elinor_Ostrom "Elinor Ostrom") and her colleagues). For instance, there is a burgeoning [neuroeconomics](https://en.m.wikipedia.org/wiki/Neuroeconomics "Neuroeconomics") literature studying brain correlates of decision-making in social dilemmas with neuroscience methods. The interdisciplinary nature of the study of social dilemmas does not fit into the conventional distinctions between fields, and demands a multidisciplinary approach that transcends divisions between [economics](https://en.m.wikipedia.org/wiki/Economics "Economics"), [political science](https://en.m.wikipedia.org/wiki/Political_science "Political science"), and [psychology](https://en.m.wikipedia.org/wiki/Psychology "Psychology").

## See also [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=23 "Edit section: See also")

-   [Belling the Cat](https://en.m.wikipedia.org/wiki/Belling_the_Cat "Belling the Cat")
-   [Collective action](https://en.m.wikipedia.org/wiki/Collective_action "Collective action")
-   [Coordination game](https://en.m.wikipedia.org/wiki/Coordination_game "Coordination game")
-   [Decision theory](https://en.m.wikipedia.org/wiki/Decision_theory "Decision theory")
-   [Elinor Ostrom](https://en.m.wikipedia.org/wiki/Elinor_Ostrom "Elinor Ostrom")
-   [Game theory](https://en.m.wikipedia.org/wiki/Game_theory "Game theory")
-   [Identity politics](https://en.m.wikipedia.org/wiki/Identity_politics "Identity politics")
-   [Moral economy](https://en.m.wikipedia.org/wiki/Moral_economy "Moral economy")
-   [Nash equilibrium](https://en.m.wikipedia.org/wiki/Nash_equilibrium "Nash equilibrium")
-   [Non-zero-sum](https://en.m.wikipedia.org/wiki/Non-zero-sum "Non-zero-sum")
-   [Prisoner's dilemma](https://en.m.wikipedia.org/wiki/Prisoner%27s_dilemma "Prisoner's dilemma")
-   [Rationality](https://en.m.wikipedia.org/wiki/Rationality "Rationality")
-   [Social trap](https://en.m.wikipedia.org/wiki/Social_trap "Social trap")
-   [Strategic games](https://en.m.wikipedia.org/wiki/Strategic_games "Strategic games")
-   [Superimposed Schedules of Reinforcement](https://en.m.wikipedia.org/wiki/Superimposed_Schedules_of_Reinforcement "Superimposed Schedules of Reinforcement")
-   [The Social Dilemma](https://en.m.wikipedia.org/wiki/The_Social_Dilemma "The Social Dilemma")
-   [Tragedy of the anticommons](https://en.m.wikipedia.org/wiki/Tragedy_of_the_anticommons "Tragedy of the anticommons")
-   [Tragedy of the commons](https://en.m.wikipedia.org/wiki/Tragedy_of_the_commons "Tragedy of the commons")
-   [Voting paradox](https://en.m.wikipedia.org/wiki/Voting_paradox "Voting paradox")
-   [Wicked problem](https://en.m.wikipedia.org/wiki/Wicked_problem "Wicked problem")
-   [Zero-sum game](https://en.m.wikipedia.org/wiki/Zero-sum_game "Zero-sum game")

## References [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=24 "Edit section: References")

1.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-1 "Jump up")** Brown, Garrett; McLean, Iain; McMillan, Alistair, eds. (2018-01-18). ["Collective action problem"](http://www.oxfordreference.com/view/10.1093/acref/9780199670840.001.0001/acref-9780199670840-e-223). _Collective action problem - Oxford Reference_. Vol. 1. Oxford University Press. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1093/acref/9780199670840.001.0001](https://doi.org/10.1093%2Facref%2F9780199670840.001.0001). [ISBN](https://en.m.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)") [9780199670840](https://en.m.wikipedia.org/wiki/Special:BookSources/9780199670840 "Special:BookSources/9780199670840"). Retrieved 2018-04-11.
2.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-2 "Jump up")** Erhard Friedberg, "Conflict of Interest from the Perspective of the Sociology of Organized Action" in _Conflict of Interest in Global, Public and Corporate Governance_, Anne Peters & Lukas Handschin (eds), Cambridge University Press, 2012
3.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-3 "Jump up")** Allison, S. T.; Beggan, J. K.; Midgley, E. H. (1996). "The quest for "similar instances" and "simultaneous possibilities": Metaphors in social dilemma research". _Journal of Personality and Social Psychology_. **71** (3): 479–497. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1037/0022-3514.71.3.479](https://doi.org/10.1037%2F0022-3514.71.3.479).
4.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-4 "Jump up")** Hobbes, Thomas. _Leviathan_.
5.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-5 "Jump up")** Hume, David. _A Treatise of Human Nature_.
6.  ^ [Jump up to: <sup><i><b>a</b></i></sup>](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-:02_6-0) [<sup><i><b>b</b></i></sup>](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-:02_6-1) Sandler, Todd (2015-09-01). ["Collective action: fifty years later"](https://doi.org/10.1007%2Fs11127-015-0252-0). _Public Choice_. **164** (3–4): 195–216. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1007/s11127-015-0252-0](https://doi.org/10.1007%2Fs11127-015-0252-0). [ISSN](https://en.m.wikipedia.org/wiki/ISSN_(identifier) "ISSN (identifier)") [0048-5829](https://www.worldcat.org/issn/0048-5829).
7.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-7 "Jump up")** Rapoport, A. (1962). The use and misuse of game theory. Scientific American, 207(6), 108–119. [http://www.jstor.org/stable/24936389](http://www.jstor.org/stable/24936389)
8.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-8 "Jump up")** ["What is Game Theory?"](https://web.archive.org/web/20180416100131/http://levine.sscnet.ucla.edu/general/whatis.htm). _levine.sscnet.ucla.edu_. Archived from [the original](http://levine.sscnet.ucla.edu/general/whatis.htm) on 2018-04-16. Retrieved 2018-04-18.
9.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-9 "Jump up")** ["Game theory II: Prisoner's dilemma | Policonomics"](http://policonomics.com/lp-game-theory2-prisoners-dilemma/). _policonomics.com_. 4 February 2013. Retrieved 2018-04-18.
10.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-10 "Jump up")** ["The Collective Action Problem | GEOG 30N: Geographic Perspectives on Sustainability and Human-Environment Systems, 2011"](https://www.e-education.psu.edu/geog30/node/342). _www.e-education.psu.edu_. Retrieved 2018-04-18.
11.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-11 "Jump up")** Rapoport, A., & Chammah, A. M. (1965). Prisoner’s Dilemma: A study of conflict and cooperation. Ann Arbor, MI: University of Michigan Press.
12.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-12 "Jump up")** Van Vugt, M., & Van Lange, P. A. M. (2006). Psychological adaptations for prosocial behavior: The altruism puzzle. In M. Schaller, J. A. Simpson, & D. T. Kenrick (Eds.), Evolution and Social Psychology (pp. 237–261). New York: Psychology Press.
13.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-13 "Jump up")** Robinson, D.R.; Goforth, D.J. (May 5, 2004). ["Alibi games: the Asymmetric Prisoner' s Dilemmas"](https://web.archive.org/web/20041206170244/http://economics.ca/2004/papers/0359.pdf) (PDF). Meetings of the Canadian Economics Association, Toronto, June 4–6, 2004. Archived from [the original](https://economics.ca/2004/papers/0359.pdf) (PDF) on December 6, 2004. Retrieved May 2, 2020.
14.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-14 "Jump up")** Beckenkamp, Martin; Hennig-Schmidt, Heike; Maier-Rigaud, Frank P. (March 4, 2007). ["Cooperation in Symmetric and Asymmetric Prisoner's Dilemma Games"](http://homepage.coll.mpg.de/pdf_dat/2006_25online.pdf) (preprint link). [Max Planck Institute for Research on Collective Goods](https://en.m.wikipedia.org/wiki/Max_Planck_Institute_for_Research_on_Collective_Goods "Max Planck Institute for Research on Collective Goods").
15.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-15 "Jump up")** Weber, M.; Kopelman, S.; Messick, D. (2004). "A conceptual Review of Decision Making in Social Dilemmas: Applying the Logic of Appropriateness". _Personality and Social Psychology Review_. **8** (3): 281–307. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1207/s15327957pspr0803\_4](https://doi.org/10.1207%2Fs15327957pspr0803_4). [PMID](https://en.m.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)") [15454350](https://pubmed.ncbi.nlm.nih.gov/15454350). [S2CID](https://en.m.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)") [1525372](https://api.semanticscholar.org/CorpusID:1525372).
16.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-16 "Jump up")** Kopelman, S (2009). "The effect of culture and power on cooperation in commons dilemmas: Implications for global resource management". _Organizational Behavior and Human Decision Processes_. **108**: 153–163. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/j.obhdp.2008.06.004](https://doi.org/10.1016%2Fj.obhdp.2008.06.004). [hdl](https://en.m.wikipedia.org/wiki/Hdl_(identifier) "Hdl (identifier)"):[2027.42/50454](https://hdl.handle.net/2027.42%2F50454).
17.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-17 "Jump up")** Allison, S. T.; Kerr, N.L. (1994). "Group correspondence biases and the provision of public goods". _Journal of Personality and Social Psychology_. **66** (4): 688–698. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1037/0022-3514.66.4.688](https://doi.org/10.1037%2F0022-3514.66.4.688).
18.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-18 "Jump up")** Baumol, William (1952). Welfare Economics and the Theory of the State. Cambridge, MA: Harvard University Press.
19.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-19 "Jump up")** Karau, Steven J.; Williams, Kipling D. (1993). "Social loafing: A meta-analytic review and theoretical integration". _Journal of Personality and Social Psychology_. **65** (4): 681–706. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1037/0022-3514.65.4.681](https://doi.org/10.1037%2F0022-3514.65.4.681). The reduction in motivation and effort when individuals work collectively compared with when they work individually or coactively
20.  ^ [Jump up to: <sup><i><b>a</b></i></sup>](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-:12_20-0) [<sup><i><b>b</b></i></sup>](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-:12_20-1) [<sup><i><b>c</b></i></sup>](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-:12_20-2) ["Public Goods: The Concise Encyclopedia of Economics | Library of Economics and Liberty"](http://www.econlib.org/library/Enc/PublicGoods.html). _www.econlib.org_. Retrieved 2018-04-18.
21.  ^ [Jump up to: <sup><i><b>a</b></i></sup>](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-:22_21-0) [<sup><i><b>b</b></i></sup>](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-:22_21-1) Banerjee, Abhijit (September 2006). ["Public Action for Public Goods"](https://economics.mit.edu/files/531).
22.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-22 "Jump up")** Schroeder, D. A. (1995). An introduction to social dilemmas. In D.A. Schroeder (Ed.), _Social dilemmas: Perspectives on individuals and groups_ (pp. 1–14).
23.  ^ [Jump up to: <sup><i><b>a</b></i></sup>](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-Frank_23-0) [<sup><i><b>b</b></i></sup>](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-Frank_23-1) Kenneth T. Frank; Brian Petrie; Jae S. Choi; William C. Leggett (2005). "Trophic Cascades in a Formerly Cod-Dominated Ecosystem". _Science_. **308** (5728): 1621–1623. [Bibcode](https://en.m.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[2005Sci...308.1621F](https://ui.adsabs.harvard.edu/abs/2005Sci...308.1621F). [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1126/science.1113075](https://doi.org/10.1126%2Fscience.1113075). [PMID](https://en.m.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)") [15947186](https://pubmed.ncbi.nlm.nih.gov/15947186). [S2CID](https://en.m.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)") [45088691](https://api.semanticscholar.org/CorpusID:45088691).
24.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-24 "Jump up")** Brechner, K. C. (1977). "An experimental analysis of social traps". _Journal of Experimental Social Psychology_. **13** (6): 552–564. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/0022-1031(77)90054-3](https://doi.org/10.1016%2F0022-1031%2877%2990054-3).
25.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-25 "Jump up")** W F Lloyd - _Two Lectures on the Checks to Population_ (1833)
26.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-26 "Jump up")** Maaravi, Yossi; Levy, Aharon; Gur, Tamar; Confino, Dan; Segal, Sandra (2021-02-11). [""The Tragedy of the Commons": How Individualism and Collectivism Affected the Spread of the COVID-19 Pandemic"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7905028). _Frontiers in Public Health_. **9**: 627559. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.3389/fpubh.2021.627559](https://doi.org/10.3389%2Ffpubh.2021.627559). [ISSN](https://en.m.wikipedia.org/wiki/ISSN_(identifier) "ISSN (identifier)") [2296-2565](https://www.worldcat.org/issn/2296-2565). [PMC](https://en.m.wikipedia.org/wiki/PMC_(identifier) "PMC (identifier)") [7905028](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7905028). [PMID](https://en.m.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)") [33643992](https://pubmed.ncbi.nlm.nih.gov/33643992).
27.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-27 "Jump up")** Platt, J (1973). "Social traps". _American Psychologist_. **28** (8): 641–651. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1037/h0035723](https://doi.org/10.1037%2Fh0035723).
28.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-28 "Jump up")** Wallace, M.D. (1979). Arms races and escalations: some new evidence. In J.D. Singer (Ed.), _Explaining war: Selected papers from the correlates of war project_ (pp. 24-252). Beverly Hills, CA: Sage.
29.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-29 "Jump up")** Tetlock, P. E. (1983). "Policy-makers' images of international conflict". _Journal of Social Issues_. **39**: 67–86. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1111/j.1540-4560.1983.tb00130.x](https://doi.org/10.1111%2Fj.1540-4560.1983.tb00130.x).
30.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-30 "Jump up")** ["Voting matters even if your vote doesn't: A collective action dilemma"](https://web.archive.org/web/20181209073429/http://blog.press.princeton.edu/2012/11/05/voting-matters-even-if-your-vote-doesnt-a-collective-action-dilemma/). _Princeton University Press Blog_. 2012-11-05. Archived from [the original](http://blog.press.princeton.edu/2012/11/05/voting-matters-even-if-your-vote-doesnt-a-collective-action-dilemma/) on 2018-12-09. Retrieved 2018-04-18.
31.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-31 "Jump up")** Kanazawa, Satoshi (2000). "A New Solution to the Collective Action Problem: The Paradox of Voter Turnout". _American Sociological Review_. **65** (3): 433–442. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.2307/2657465](https://doi.org/10.2307%2F2657465). [JSTOR](https://en.m.wikipedia.org/wiki/JSTOR_(identifier) "JSTOR (identifier)") [2657465](https://www.jstor.org/stable/2657465).
32.  ^ [Jump up to: <sup><i><b>a</b></i></sup>](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-:32_32-0) [<sup><i><b>b</b></i></sup>](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-:32_32-1) Duit, Andreas (2011-12-01). "Patterns of Environmental Collective Action: Some Cross-National Findings". _Political Studies_. **59** (4): 900–920. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1111/j.1467-9248.2010.00858.x](https://doi.org/10.1111%2Fj.1467-9248.2010.00858.x). [ISSN](https://en.m.wikipedia.org/wiki/ISSN_(identifier) "ISSN (identifier)") [1467-9248](https://www.worldcat.org/issn/1467-9248). [S2CID](https://en.m.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)") [142706143](https://api.semanticscholar.org/CorpusID:142706143).
33.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-33 "Jump up")** ["A Majority Says that Government Regulation of Business Does More Harm than Good"](https://www.pewresearch.org/fact-tank/2012/03/07/a-majority-says-that-government-regulation-of-business-does-more-harm-than-good/). _Pew Research Center_. 2012-03-07. Retrieved 2018-04-18.
34.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-34 "Jump up")** Van Vugt, M.; Meertens, R. & Van Lange, P. (1995). ["Car versus public transportation? The role of social value orientations in a real-life social dilemma"](https://web.archive.org/web/20110715120238/http://www.professormarkvanvugt.com/files/CarVersusPublicTransportation-JournalofAppliedSocialPsychology-1995.pdf) (PDF). _Journal of Applied Social Psychology_. **25** (3): 358–378. [CiteSeerX](https://en.m.wikipedia.org/wiki/CiteSeerX_(identifier) "CiteSeerX (identifier)") [10.1.1.612.8158](https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.612.8158). [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1111/j.1559-1816.1995.tb01594.x](https://doi.org/10.1111%2Fj.1559-1816.1995.tb01594.x). Archived from [the original](http://www.professormarkvanvugt.com/files/CarVersusPublicTransportation-JournalofAppliedSocialPsychology-1995.pdf) (PDF) on 2011-07-15.
35.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-35 "Jump up")** Orbell, John M.; Dawes, Robyn M. & van de Kragt, Alphons J. C. (1988). "Explaining discussion-induced cooperation". _Journal of Personality and Social Psychology_. **54** (5): 811–819. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1037/0022-3514.54.5.811](https://doi.org/10.1037%2F0022-3514.54.5.811).
36.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-36 "Jump up")** Razmerita, Liana; Kirchner, Kathrin; Nielsen, Pia (2016). ["What factors influence knowledge sharing in organizations? A social dilemma perspective of social media communication"](https://research-api.cbs.dk/ws/files/45013819/liana_razmerita_what_factors_influence_postprint.pdf) (PDF). _Journal of Knowledge Management_. **20** (6): 1225–1246. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1108/JKM-03-2016-0112](https://doi.org/10.1108%2FJKM-03-2016-0112). [hdl](https://en.m.wikipedia.org/wiki/Hdl_(identifier) "Hdl (identifier)"):[10398/e7995d52-ccc3-4156-b131-41e5908d0e63](https://hdl.handle.net/10398%2Fe7995d52-ccc3-4156-b131-41e5908d0e63). [S2CID](https://en.m.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)") [36485882](https://api.semanticscholar.org/CorpusID:36485882).
37.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-Nowak_&_Sigmund,_1992_37-0 "Jump up")** Nowak, M. A.; Sigmund, K. (1992). ["Tit for tat in heterogeneous populations"](https://web.archive.org/web/20110616192929/http://www.ped.fas.harvard.edu/people/faculty/publications_nowak/Nature92b.pdf) (PDF). _Nature_. **355** (6357): 250–253. [Bibcode](https://en.m.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[1992Natur.355..250N](https://ui.adsabs.harvard.edu/abs/1992Natur.355..250N). [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1038/355250a0](https://doi.org/10.1038%2F355250a0). [S2CID](https://en.m.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)") [4281385](https://api.semanticscholar.org/CorpusID:4281385). Archived from [the original](http://www.ped.fas.harvard.edu/people/faculty/publications_nowak/Nature92b.pdf) (PDF) on 2011-06-16.
38.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-38 "Jump up")** Ostrom, Elinor (1990). _Governing the Commons:The Evolution of Institutions for Collective Action_. Cambridge University Press.
39.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-39 "Jump up")** Poteete, Janssen, and Ostrom (2010). _Working Together: Collective Action, the Commons, and Multiple Methods in Practice_. Princeton University Press.
40.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-40 "Jump up")** Yamagishi, T. (1986). "The Provision of a Sanctioning System as a Public Good". _Journal of Personality and Social Psychology_. **51** (1): 110–116. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1037/0022-3514.51.1.110](https://doi.org/10.1037%2F0022-3514.51.1.110).
41.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-41 "Jump up")** Mulder, L.B.; Van Dijk, E.; De Cremer, D.; Wilke, H.A.M. (2006). "Undermining trust and cooperation: The paradox of sanctioning systems in social dilemmas". _Journal of Experimental Social Psychology_. **42** (2): 147–162. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/j.jesp.2005.03.002](https://doi.org/10.1016%2Fj.jesp.2005.03.002).
42.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-42 "Jump up")** Ostrom, Elinor (1990). _Governing the Commons_.
43.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-43 "Jump up")** Poteete; et al. (2010). _Working Together_.
44.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-44 "Jump up")** Van Vugt, M. & De Cremer, D. (1999). ["Leadership in social dilemmas: The effects of group identification on collective actions to provide public goods"](https://pure.uvt.nl/ws/files/654858/JPSP1999_MarkDave_.pdf) (PDF). _Journal of Personality and Social Psychology_. **76** (4): 587–599. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1037/0022-3514.76.4.587](https://doi.org/10.1037%2F0022-3514.76.4.587).
45.  ^ [Jump up to: <sup><i><b>a</b></i></sup>](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-Ostrom_2009_419%E2%80%93422_45-0) [<sup><i><b>b</b></i></sup>](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-Ostrom_2009_419%E2%80%93422_45-1) Ostrom, Elinor (24 July 2009). "A General Framework for Analyzing Sustainability of Social-Ecological Systems". _Science_. **325** (5939): 419–422. [Bibcode](https://en.m.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[2009Sci...325..419O](https://ui.adsabs.harvard.edu/abs/2009Sci...325..419O). [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1126/science.1172133](https://doi.org/10.1126%2Fscience.1172133). [hdl](https://en.m.wikipedia.org/wiki/Hdl_(identifier) "Hdl (identifier)"):[11059/14638](https://hdl.handle.net/11059%2F14638). [PMID](https://en.m.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)") [19628857](https://pubmed.ncbi.nlm.nih.gov/19628857). [S2CID](https://en.m.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)") [39710673](https://api.semanticscholar.org/CorpusID:39710673).
46.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-46 "Jump up")** see for example Gunnthorsdottir, A. and Rapoport, A. (2006). "Embedding social dilemmas in intergroup competition reduces free-riding". _Organizational Behavior and Human Decision Processes_. **101** (2): 184–199, also contains a survey of the relevant literature. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/j.obhdp.2005.08.005](https://doi.org/10.1016%2Fj.obhdp.2005.08.005).
47.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-47 "Jump up")** Ostrom, Elinor (25 September 2007). ["A diagnostic approach for going beyond panaceas"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2000497). _Proceedings of the National Academy of Sciences_. **104** (39): 15181–15187. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1073/pnas.0702288104](https://doi.org/10.1073%2Fpnas.0702288104). [PMC](https://en.m.wikipedia.org/wiki/PMC_(identifier) "PMC (identifier)") [2000497](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2000497). [PMID](https://en.m.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)") [17881578](https://pubmed.ncbi.nlm.nih.gov/17881578).
48.  **[^](https://en.m.wikipedia.org/wiki/Collective_action_problem#cite_ref-48 "Jump up")** Poteete, Janssen, and Ostrom (2010). _Working Together: Collective Action, the Commons, and Multiple Methods in Practice_. Princeton University Press. p. 228.

## Further reading [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=25 "Edit section: Further reading")

-   Axelrod, R. A. (1984). _The evolution of cooperation_. New York: Basic Books. [ISBN](https://en.m.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)") [978-0-465-02122-2](https://en.m.wikipedia.org/wiki/Special:BookSources/978-0-465-02122-2 "Special:BookSources/978-0-465-02122-2").
-   Batson, D. & Ahmad, N. (2008). ["Altruism: Myth or Reality?"](https://web.archive.org/web/20080517041239/http://www.in-mind.org/issue-6/altruism-myth-or-reality.html). _In-Mind Magazine_. **6**. Archived from [the original](http://www.in-mind.org/issue-6/altruism-myth-or-reality.html) on 2008-05-17.
-   Dawes, R. M. (1980). "Social dilemmas". _Annual Review of Psychology_. **31**: 169–193. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1146/annurev.ps.31.020180.001125](https://doi.org/10.1146%2Fannurev.ps.31.020180.001125).
-   ——— & Messick, M. (2000). "Social Dilemmas". _[International Journal of Psychology](https://en.m.wikipedia.org/wiki/International_Journal_of_Psychology "International Journal of Psychology")_. **35** (2): 111–116. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1080/002075900399402](https://doi.org/10.1080%2F002075900399402).
-   Kollock, P. (1998). "Social dilemmas: Anatomy of cooperation". _Annual Review of Sociology_. **24**: 183–214. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1146/annurev.soc.24.1.183](https://doi.org/10.1146%2Fannurev.soc.24.1.183). [hdl](https://en.m.wikipedia.org/wiki/Hdl_(identifier) "Hdl (identifier)"):[20.500.12749/3338](https://hdl.handle.net/20.500.12749%2F3338). [JSTOR](https://en.m.wikipedia.org/wiki/JSTOR_(identifier) "JSTOR (identifier)") [223479](https://www.jstor.org/stable/223479).
-   Komorita, S. & Parks, C. (1994). _Social Dilemmas_. Boulder, CO: Westview Press. [ISBN](https://en.m.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)") [978-0-8133-3003-7](https://en.m.wikipedia.org/wiki/Special:BookSources/978-0-8133-3003-7 "Special:BookSources/978-0-8133-3003-7").
-   Kopelman, S., Weber, M, & Messick, D. (2002). [Factors Influencing Cooperation in Commons Dilemmas: A Review of Experimental Psychological Research](http://www.nap.edu/catalog.php?record_id=10287). In E. Ostrom et al., (Eds.) The Drama of the Commons. Washington DC: National Academy Press. Ch. 4., 113–156
-   Kopelman, S. (2009). ["The effect of culture and power on cooperation in commons dilemmas: Implications for global resource management"](https://deepblue.lib.umich.edu/bitstream/2027.42/50454/4/1072r_08_Kopelman.pdf) (PDF). _Organizational Behavior and Human Decision Processes_. **108**: 153–163. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/j.obhdp.2008.06.004](https://doi.org/10.1016%2Fj.obhdp.2008.06.004). [hdl](https://en.m.wikipedia.org/wiki/Hdl_(identifier) "Hdl (identifier)"):[2027.42/50454](https://hdl.handle.net/2027.42%2F50454).
-   Messick, D. M. & Brewer, M. B. (1983). "Solving social dilemmas: A review". In Wheeler, L. & Shaver, P. (eds.). _Review of personality and social psychology_. Vol. 4. Beverly Hills, CA: Sage. pp. 11–44.
-   Nowak, M. A.; Sigmund, K. (1992). ["Tit for tat in heterogeneous populations"](https://web.archive.org/web/20110616192929/http://www.ped.fas.harvard.edu/people/faculty/publications_nowak/Nature92b.pdf) (PDF). _Nature_. **355** (6357): 250–253. [Bibcode](https://en.m.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[1992Natur.355..250N](https://ui.adsabs.harvard.edu/abs/1992Natur.355..250N). [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1038/355250a0](https://doi.org/10.1038%2F355250a0). [S2CID](https://en.m.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)") [4281385](https://api.semanticscholar.org/CorpusID:4281385). Archived from [the original](http://www.ped.fas.harvard.edu/people/faculty/publications_nowak/Nature92b.pdf) (PDF) on 2011-06-16.
-   Palfrey, Thomas R. & Rosenthal, Howard (1988). "Private Incentives in Social Dilemmas: The Effects of Incomplete Information and Altruism". _Journal of Public Economics_. **35** (3): 309–332. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/0047-2727(88)90035-7](https://doi.org/10.1016%2F0047-2727%2888%2990035-7).
-   Ridley, M. (1997). _Origins of virtue_. London: Penguin Classics. [ISBN](https://en.m.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)") [978-0-670-87449-1](https://en.m.wikipedia.org/wiki/Special:BookSources/978-0-670-87449-1 "Special:BookSources/978-0-670-87449-1").
-   Rothstein, B. (2003). _Social Traps and the Problem of Trust_. Cambridge: Cambridge University Press. [ISBN](https://en.m.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)") [978-0521612821](https://en.m.wikipedia.org/wiki/Special:BookSources/978-0521612821 "Special:BookSources/978-0521612821").
-   Schneider, S. K. & [Northcraft, G. B.](https://en.m.wikipedia.org/wiki/Gregory_Northcraft "Gregory Northcraft") (1999). "Three social dilemmas of workforce diversity in organizations: A social identity perspective". _Human Relations_. **52** (11): 1445–1468. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1177/001872679905201105](https://doi.org/10.1177%2F001872679905201105). [S2CID](https://en.m.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)") [145217407](https://api.semanticscholar.org/CorpusID:145217407).
-   Van Lange, P. A. M.; Otten, W.; De Bruin, E. M. N. & Joireman, J. A. (1997). ["Development of prosocial, individualistic, and competitive orientations: Theory and preliminary evidence"](https://research.vu.nl/ws/files/570774/VanLange%20Journal%20of%20Personality%20and%20Social%20Psychology%2073(4)%201997%20u.pdf) (PDF). _Journal of Personality and Social Psychology_. **73** (4): 733–746. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1037/0022-3514.73.4.733](https://doi.org/10.1037%2F0022-3514.73.4.733). [hdl](https://en.m.wikipedia.org/wiki/Hdl_(identifier) "Hdl (identifier)"):[1871/17714](https://hdl.handle.net/1871%2F17714). [PMID](https://en.m.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)") [9325591](https://pubmed.ncbi.nlm.nih.gov/9325591).
-   Van Vugt, M. & De Cremer, D. (1999). ["Leadership in social dilemmas: The effects of group identification on collective actions to provide public goods"](https://pure.uvt.nl/ws/files/654858/JPSP1999_MarkDave_.pdf) (PDF). _Journal of Personality and Social Psychology_. **76** (4): 587–599. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1037/0022-3514.76.4.587](https://doi.org/10.1037%2F0022-3514.76.4.587).
-   Weber, M.; Kopelman, S. & Messick, D. M. (2004). "A conceptual review of social dilemmas: Applying a logic of appropriateness". _Personality and Social Psychology Review_. **8** (3): 281–307. [doi](https://en.m.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1207/s15327957pspr0803\_4](https://doi.org/10.1207%2Fs15327957pspr0803_4). [PMID](https://en.m.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)") [15454350](https://pubmed.ncbi.nlm.nih.gov/15454350). [S2CID](https://en.m.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)") [1525372](https://api.semanticscholar.org/CorpusID:1525372).
-   Yamagishi, T. (1986). "The structural goal/expectation theory of cooperation in social dilemmas". In Lawler, E. (ed.). _Advances in group processes_. Vol. 3. Greenwich, CT: JAI Press. pp. 51–87. [ISBN](https://en.m.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)") [978-0-89232-572-6](https://en.m.wikipedia.org/wiki/Special:BookSources/978-0-89232-572-6 "Special:BookSources/978-0-89232-572-6").

## External links [edit](https://en.m.wikipedia.org/w/index.php?title=Collective_action_problem&action=edit&section=26 "Edit section: External links")

-   [Homepage of the social-dilemma network](http://www.socialdilemma.com/)
