---
note_type: metamedia
mm_source: youtube
mm_url: https://www.youtube.com/watch?v=3eG5JwHrn6s
---

# Video
Greg Scontras â€“ The pragmatics of truth-value judgments
![](https://www.youtube.com/watch?v=3eG5JwHrn6s)

## Transcript:
you

thank you very much thank you for having
me thank you for coming on this very
special day so I am planning to talk
about some work on cognitive modeling as
it relates to intersections with
linguistic theory and experimental
linguistics and I'm betting that the
framework that I'll be operating within
and presenting to you about today is
going to be unfamiliar to many of you so
I'm perfectly happy to take questions of
clarification throughout the talk okay
so don't hesitate to ask questions if
things aren't clear I purposefully put
less than I thought would fill up at the
time so don't worry about that if
however I sense that we are veering down
some dangerous rabbit hole I might put
off that question until the end of the
talk so don't be shy we can have a
conversation that's fine now the first
thing to note about what I'm talking
about today is that a disjoint work with
KJ's how nelly and lisa pearl we're all
at UC irvine and we're thinking about
the pragmatics of truth value judgments
or as i like to think about it a
cautionary tale for truth value
judgments now for the working samantha's
truth value judgments are crucial to the
extent that you have associate meaning
say the meaning of a sentence with its
truth conditions whatever we take for
that sentence
true these truth value judgments are
critical for mapping out the truth
conditions of these sentences you can
define the boundaries of true and false
using these truth value judgments so
they're very useful to us as working the
semantic cyst but they are not without
their pitfalls and I'm going to talk
about some of those today
the trick is now that experimental
semantics is taking hold you might think
that oh I can gain insight and solve all
of my problems by just running an
experiment I'll let you decide after the
talk whether or not I'm giving you
advice to run experiments or tube now
experiment I'm not entirely sure that
I've decided that for myself with
respect to these truth value judgments
but I'll at least present to you some of
the terrain of why these things are
difficult but first what is a truth
value judgment so suppose you're in a
world that has three horses horse one
horse two and verse three and suppose
that horse one jumps over a fence and
then horse two jumps over the fence but
horse three decides that she's not going
to jump over the fence okay so this is
what we know about the world and the
resulting world state has two out of
those three horses jumping over the
fence okay this is the state of the
world that we observed now suppose Mary
here comes in and describes the state of
the world as follows
every horse didn't jump over the fence
did Mary's be truthfully or not how
would you you think that Mary's boat
okay good
how many of you think not interesting
there's some fascination good so this is
a truth value judgment deciding so this
is a truth value judgment you have to
decide whether or not this sentence
truthfully describes the scenario you
have options like true or false you
might think of this as endorsing Mary's
description of this state of affairs or
choosing not to endorse this state of
affairs
now here the majority of you endorsed
this utterance as a description of the
state of affairs which is good because
the majority of you are adults adults
endorse this sentence essentially all
except for the logicians children almost
never endorse this veterans now I have a
picture of a relatively young child here
because this picture was cuter than the
picture of the five year olds who they
usually test in this experiment but
these numbers are for kids around the
age of five okay so kids do not endorse
the utterance adults do endorse the
utterance and the question is why what's
going on now the thing to observe about
the sentence every horse didn't jump
over the fence is that it is awfully
ambiguous there are two scope very
operators at least in this sentence I've
got every this Universal animal
and I've got buttons and didn't which is
negation and depending on the relative
scope of those operators I'm going to
get two different interpretations or two
different sets of truth conditions so
when I have the universal logically
scoping over the negation as in the case
of the linear order of those words in
the sentence I'm going to have an
interpretation where I say for every
course that is not the case that the
course jumped over the fence
this I will gloss as the nun
interpretation it is known as the
surface interpretation because the or of
these quantifiers that logical format
matches the order of those quantifiers
at service structure or in the linear
order of those words in the sentence but
that's not the only option you also have
what's known as an inverse
interpretation where now I'm
interpreting these scope bearing
elements in an order that is opposite to
what I observe in the service structure
of that sentence so here I'm saying it
is not the case that for all forces
those forces jumped over the fence
I will loss this as the so I've got the
surface interpretation where every take
scope over negation none of the horses
jumped I've got the inverse
interpretation where negation please go
over every not all of them were since
jumped okay so maybe what we should
conclude is that adults who readily
endorse this utterance are perfect
perfectly capable of accessing that
inverse interpretation why here two out
of three horses jumped over the fence it
is certainly not the case that none of
the horses jumped two of them did but it
is the case that not all of the horses
jumped one of those horses didn't so it
is not
that all of ours has jumped so the
inverse interpretation adults can access
that great we're off and running kids
who do not endorse this sentence may be
our perseverating on this surface parse
of the sentence and so they can't see
that it could be true under this inverse
interpretation so you might conclude
that the children cannot access the
inverse interpretation now that would be
very nice if that would be in this story
but that is not the end of the story
because in fact we can make kids a lot
more adult-like
by changing aspects of the task itself
so here are some changes that are going
to get you higher utterance so instead
of just presenting children with the
target sentence every horse didn't jump
over the fence I first introduced an
explicit contrast clause so now what the
children see is every horse jumped over
the log so they see a preceding story
where all of the horses jumped over the
log they're given the sentence every
horse jumped over the log but every
horse didn't jump over the fence and now
his endorsement rates jump to around 60%
that's a huge shift the change here
being I've given you this explicit
contrast class so why should that be to
greater rates of endorsement you see the
same effect of the explicit contrast
without actually putting in the explicit
contrast what do I mean by that in the
preceding story context if I have a
whole bunch of early successes and then
I give you the target sentence you're
still going to get lots of endorsements
still at the rate of 60% so here's what
that story context map
but three horses decide to have some fun
jumping over things the experimenters
are actually acting this out with
puppets
one horse jumps over a cow and the
challenges the other two horses to do
the same the other horses jump over the
cow one after the other then the first
horse jumps over the pig and challenges
the other courses to do the same the
second horse jumps it with a pig the
third horse considers jumping over the
pig but decides that the pig looks
scared and approaches him the pig is in
fact scared
so the third horse just walks with him
instead of jumping over him these the
materials that we're doing so the target
sentence in this case would be every
horse didn't jump over the pig there is
no explicit contrast but I've got that
early success story and the kids
endorsement rate is significantly higher
than the baseline 60y here's something
else that you can do to increase
utterance endorsement here you can give
what the experimenters take to be an
unambiguous prime of the logical form
we'll come back to that and if I say now
not every horse jumped over the pig so
you've got those supporting contexts for
that but every horse didn't jump over
the fence kids utterance endorsement
rates are around 80% okay so this is
something else that we can do to
increase these endorsements and lastly
you can try and manipulate the goal of
the task so if for example instead of
talking about horses jumping we're
talking about say some man some farmer
trying to find specific horses now
suppose that the farmer has found two
out of the three horses that's why that
third horse is obscured the target
sentence is going to be the man didn't
fire
courses where now I've got the negation
that didn't and I've got the existential
quantifier and I want the inverse
interpretation where there are some
horses that the man didn't find that
would be true in this case you didn't
find horse number three adults will
endorse this kids in the baseline will
not but if I can convince you that in
this story it is relevant whether or not
the man found all of the horses then the
utterance endorsement rate is going to
jump up to about eighty percent so if I
can manipulate the goals of the people
in this story okay
so here is a look at the empirical
landscape at least according to these
authors of the experiments themselves so
we've seen four manipulations to the
experiment that lead to greater
utterance endorsement rates the explicit
contracts clause the early success story
contact priming the goal itself and the
unambiguous priming of the logical form
now according to the authors here is
what those things are doing the first
three are leading to a satisfaction of
the felicity conditions of the nation so
if I tell you every horse didn't jump
over the fence there's got to be a
reason why you're going to the trouble
of negating that sentence as opposed to
just telling me something positive in
the first place you've got to be
contrasting it with something this is
what they think okay all of those three
manipulations allows you to satisfy
those felicity conditions of the
negation with the unambiguous priming
the authors say you are explicitly
priming the logical form the relative
scoping of those
at logical form so if you encounter one
logical form with a specific scoping of
those quantifiers then maybe later on
that specific arrangement is going to be
more accessible this is what's going on
now unfortunately upon further scrutiny
this is a serious idealization of what
is actually changing in these
experiments so let's think about what is
actually changing in these experiments
starting with the explicit contrast
clause I tell you now that every course
jumped over the log and I've given you
the supportive context but every course
first of all I've given you information
additional information about the jumping
ability of those horses now I know that
those horses are perfectly capable of
jumping over things namely the lock this
is just on at face value things that are
changing as I'm changing these
experiments whether or not this is going
to lead to the actual cognitive
mechanisms that are going to change we
can test that later but its face value
here I've changed something I've given
you information about the horses and
their job I also might have pushed
around your knowledge and or
expectations of the question under
discussion or QUT so maybe the baseline
question under discussion is what is the
state of the world how many horses
jumped I want to know what the role is
maybe by telling you every horse jumped
over the log now all of a sudden you
want to know whether or not every horse
jumped over the fence so now the qud has
shifted from how many horses jumped over
the fence to did every
so in addition to give you new
information about forces and their
jumping ability I might be pushing
around your expectations for the
relevant QUT question under discussion
in this scenario you seemed dissatisfied
no it's very satisfied okay good now
this is what the expressive it explicit
contrast clause the exact same holds
with the early success story right the
early success story is the same as the
explicit contrast clause I just don't
have the explicit contrast clause in
that test sentence so in that early
success story I am giving you
information about horses and their
jumping ability which might affect your
world knowledge about horses and it
might push around your expectations
about what the question every discussion
is in the case of the unambiguous
priming it could very well be the case
that I am increasing or decreasing the
accessibility of specific logical forms
of the specific arrangements of these
quantifiers at logical form but it is
also the case that I am giving you
information about horses and their
jumping and I could be pushing around
your expectations for whatever question
is under discussion not every horse
jumped over the pig
well did every horse jump over the fence
and that they are affecting more than
just the specific aspects of this
utterance disambiguation that the
authors think they might be affecting in
the case of the goal priming so if I
somehow make it relevant whether or not
the man found all of the horses and then
tell you that the man didn't find some
of the horses here presumably what I'm
effecting is your expectations about the
question under discussion the Quixote so
if I tell you the man wants to know or
Mary wants to know whether or not the
man found all the horses than the qd1
would hope is did the man find all of
the horses so here's what the picture
actually looks like you've got these and
they seem to be affecting various things
our world knowledge our expectations
about the conversational topic or
question under discussion and the
accessibility of a specific logical or
now if you think about these three
factors they split broadly on the basis
of whether or not we're dealing with
pragmatic factors so what we know about
the world and what we think to be the
relevant question under discussion let's
call those things pragmatic factors
factors about the use of language in
context versus grammatical or processing
factors how easy it is for me to access
the specific logical form what I would
like to do what we wanted to do and what
we think we made some progress in doing
is figuring out how we can use the
potentially independent contributions of
these factors to the complicated process
of utterance disambiguation there's a
whole lot that goes into disambiguating
an utterance
contests these factors among them and
the question is how can we isolate what
could be an independent contribution
from any one of these factors in this
morass of utterance disability
disambiguation well what we're going to
need is a pretty beefy tool and here is
the tool that we use we used computers
with which to develop computational
cognitive models of the utterance
disambiguation process so what we wanted
was an explicit articulated formal model
of start to finish how it is that you go
about performing these truth value
judgments and disambiguating these
utterances now the model that we
developed is created within what's known
as the rational speech act modeling
framework are any of you familiar with
the rational speech act framework so the
rational speech act I work for RSA views
language understanding as recursive
social reasoning between speakers and
listeners so I listen er interpret an
utterance by reasoning about how you a
speaker would choose an utterance to
communicate to a listener who is
interpreting the utterance by reasoning
about a speaker who is choosing that
utterance by reasoning about a listener
etc okay so the speaker and the listener
are coordinating during this language
understanding process they're
coordinating on the utterance and
interpretation that is most likely to
correctly resolve the question under
discussion we're again in the basic case
the question under discussion would be
what is the state of the world that you
the speaker are observing that you were
trying to communicate so the speaker
observes the state of the world and
shoes
and that would communicate that state of
the world to listener who is
interpreting that veterans now for those
of you who are not familiar with the RSA
framework this is my favorite joke that
I get to tell my students the good news
is it's just math and that's also the
bad news so we're going to go through
the math but first let me give you the
intuitions that this RSA framework was
developed to capture in the first place
so this is just basic vanilla RSA so
suppose you're in a world where you've
got a blue square you've got a blue
circle and you've got a green square and
you the speaker observe that you are
pointing to the blue circle okay so the
state of the world is I am pointing to
the blue circle and now you the speaker
want to communicate that state of the
world to a listener and you the speaker
have to choose between the word blue and
the word circle what will you say how
many of you are going to say blue okay
how many of you were gonna say circle
it's very good okay so why we're gonna
say circle in this case why are we going
to say circle presumably this is going
to involve lots of counterfactual
reasoning while if I had said blue then
the listener would have been less likely
to correctly arrive at the circle that I
am intending but circle is the only
thing that is going to uniquely define
this thing so I know this is a nice
prose description of how we might think
this yeah we want to formally err okay
so this is speaker behavior here's
listener behavior now you have three
options for what the state of the world
is which one of those things is being
indicated by the speaker and you here
blue so I'm going to rule out the green
square how many of you think that the
speaker is trying to signal new circle
how many of you think that the speaker
is trying to the signal okay and now of
course the question is why and here we
go back to this counterfactual reasoning
well if the speaker had wanted to signal
the circle the speaker could have just
said circle and I would have known it
was the circle with 100% probability but
the speaker did not say circle the
speaker said blue so given that the
speaker is probably not talking about
the circle there's only one other blue
thing there he probably wouldn't say
Square because there are two and again
you go into this deep recursive
reasoning about what could have been
said what should have been said what was
said and what you think is actually
going on there right so we want to model
this reasoning process such that we can
capture the independent contributions to
this reasoning process and make some
predictions and try and understand
behavior so in the RSA framework you've
got these nested levels of four literal
listener here is what the literal
listener does it's just math so the
literal listener
observes some utterance I hear another
and what I do is I resolve the QD I
infer what the state of the world is
that that utterance could be truthfully
described so the literal listener is
going to return a distribution over
states of the world that that utterance
could literally describe how does the
literal literal listener generate that
belief distribution by updating his
beliefs so I have some prior beliefs of
which states of the world I think are
more or less likely I have the literal
semantics of that utterance and I use
that to return a distribution of states
of the world that
Durin's could truthfully describe here
is the quick and dirty introduction to
truth-functional semantics for those of
you who might not be familiar so this is
what powers the literal listener can you
truthfully describe ask here is how that
semantics works suppose I have the
utterance blue it's gonna map the Blue
Square to true it's going to map the
blue circle to true it's gonna map the
Green Square to false okay now you know
truth functional semantics if you didn't
so that's what's powering the literal
listener in this so those states that
could be truthfully distract waited by
whatever prior probability I have about
States in general that's going to return
for me a belief distribution over states
that that utterance is literally
described that's the literal listener we
are not the neural ism
this is some idealization about how we
think speakers behave the next level up
is going to be a speaker a pragmatic
speaker he chooses utterances to
communicate some state of the world to
that naive literal listener
so here is how the speaker names the
speaker observes the state of the world
I'm pointing at this thing and the
speaker returns a distribution over
audiences that could communicate that
state of the world to the literal
listener okay so the speaker is
reasoning directly about the behavior of
that literal listener this math is a
soft max optimization of choosing the
utterance that is most likely to lead
that literal listener to the correct
world sing so the speakers aren't
perfectly optimal how the business is
going to control for those of you who
are familiar with sentence processing
what the speaker is trying to do is
minimize the surprise of that state of
the world given the utterance that the
literal listener is observing so in
effect I'm a speaker I want to maximize
the probability
that the literal listener arrives at the
correct state given the utterance
however I'm lazy so I want to minimize
the cost of the veterans itself and by
trading these two things off each other
efficiency and efficacy we can increase
we're lazy if we have a pretty good shot
with a cheap utterance that you will
arrive at the thing that I want you to
arrive at I'll use that cheap utterance
okay so that's how the speaker works the
speaker observes the state chooses an
utterance to communicate that state to
this naive literal listener now at the
top level of reason you have what's
known as the pragmatic listener that's
your eye as we interpret language we're
very sophisticated so we wear a hat what
we do is the same thing as the listener
we observe in other words we hear the
utterance and we infer what the state of
the world is that that utterance is
describing but rather than reasoning
directly about the semantics we reason
about the process that generated B
mutterings in the first place okay so
I'm a literal listener here the
utterance and I think AHA how would the
speaker have chosen that utterance which
state was that speaker most likely to
have observed that led him to choose
that utterance
so I interpret that other it's by
reasoning about the speaker who is
reasoning about the literal listener who
is updating beliefs about the state of
the world so semantics is still playing
a crucial role here but it is rather
indirect from the perspective of the
pragmatic listener first I have to think
about the generator
that led to that veterans and through
that I can reason about the semantics
okay so here is a proposal here is a
model for how it is that we interpret
language this is the basic vanilla
rational speech act RSA model you're
looking at it that's the whole thing
there so now let's think about
predictions in the toilet scenario that
we considered first so first we have
this literal listener the literal
listener observes the utterance blue I
have to create a belief distribution of
states of the world that that utterance
could truthfully describe what is that
between distribution granular level now
you have to speak I heard blue I'm the
literal listener let's suppose that all
of those objects were a priori equally
likely what is my belief distribution is
going to look like 50/50 on one and the
two blue items on the Blue Square and
the blue circle and that's exactly what
we're going to get in terms of
predictions out of this RS a literal
listener layer okay so here's the blue
circle here's the Blue Square and I'm a
chance between those two things this is
what my beliefs look like as the literal
listener now we go up to the speaker now
let's say the speaker observes the blue
circle as the state of the world and
tries to choose between the words blue
and circle those be only words that
would literally describe this here is
how this speaker
so this is the speaker's distribution
over utterances to describe that state
to the literal listener and now the
speaker is a little bit more likely to
say circle than to say blue why because
the speaker knows how that literal
listener is going to behave and the
speaker knows if I say circle then with
a hundred percent probability the
literal listener is going to arrive at
the correct state of the world if I were
to say blue there is still a chance that
that literal listener could arrive at
the true state of the world so there is
some probability mass on that but that
chance is 50-50 so it's not as good of
an option as I increase the optimality
of the speaker with this temperature
parameter here you're going to see more
maximizing behavior and that speakers
only ever going to choose okay so I am
already starting to break the symmetry
in these and now when I get up to the
pragmatic listener things get
interesting so here I'm the pragmatic
listener I'm trying to infer the state
of the world
I hear blue and now I am more likely to
infer that the speaker is talking about
the Blue Square in the blue circle these
were the intuitions that you shared with
me and now we have a model of why that
is happening because the pragmatic
listener has a model of the speaker and
pragmatic listener knows well if the
speaker wanted to talk about the blue
circle the speaker would have said
circle the speaker did not say circle
the speaker said blue instead so the
speaker probably intends so this is the
belief
distribution broken symmetry we've
calculated what's known as the
specificity of nature good so vanilla RS
a very good at calculating and print
implicatures not going to handle
ambiguity for us in order to model
ambiguity resolution we need to
complicate this model a little bit here
is how I am complicating in terms of
describing this distribution here yeah
so cheating because at some point you're
going to have to choose a single action
that makes you or just uncomfortable
it feels like it should be either way I
mean you could have a distribution all
the speakers already pragmatic whatnot I
mean so this is a prediction that says
68% of the time that speaker is going to
say circle yeah 32% of the time so you
can think about the speaker action as
sampling from this distribution and 68%
of the time that speaker will sample an
action and wind up with circle and say
circle and 32% of the time that speaker
is going to sample blue in say blue so
that's how but what you're touching on
is a much deeper question if I'm
interpreting this correctly which is
what are we modeling are we modeling
individual speakers are we modeling the
general speaker behavior process the RSA
framework was designed to model the
general behavioral process across the
population now that is not to say that
it cannot model individual speaker
behavior but this was explicitly not
designed to do that there is some work
trying to push RSA in that direction
this isn't it
okay but what this says is if I have a
hundred speakers than sixty eight of
them should say circle and 32 of them
should say blue and the reason why this
framework has there
is amazingly accurate when it comes to
predicting so it's doing something right
at the population level at the
individual level we just don't have the
empirical is that more satisfying well
so the reason why I'm not really
comfortable with that terminology is
both of these choices are literal yeah
one of them is a bit more pragmatic than
the other there at this point I haven't
shown you a way for RSA to handle non
literal language now spoil alert that
can but we're not going to talk about
that today so think about this as a
distribution over possible actions that
you are going to sample from whenever
you take an action and so there are 68
circle balls in my bag and then there
are 32 blue balls in my bag and I'm
going to pull one of those balls out
look at it and say AHA this is what I'm
going to say to try and communicate this
to the listener it's even worse than she
thinks in the sense that basically you
treat every utterance as it were from a
new speaker of this there's no
resistance
think about this from across time for
multilaterally and killed yet no no way
of knowing who the next aspirants is
coming from there's nothing no such
thing as so basically the population of
utterances and not speakers these models
have no so I can't remember what I have
done when you have done what anyone else
has done what I couldn't do in a single
one-off case is a model what I think you
were like as I'm choosing my behavior so
that is certainly possible that's not
outside the bounds here but memory is
nowhere in RSA at this point better or
worse but yeah so to the extent that you
think that we can define individuals on
the basis of their histories of behavior
this isn't in there right we are just
generalizing across the population and
it does a good job ok so we were at the
basic RSA model and now in order to
model ambiguity resolution
I need my remote to work
so this is what I so what I'm going to
show you now is what's known as a lifted
variable variant of the RSA framework so
what I've done is I have parameterised
the interpretation function here by some
variable T the literal listener is now
going to observe the utterance and that
interpretation fixing variable V and
behave as normal nothing funny here the
literal listener just interprets the
utterance with respect that parameter
and returns a distribution over States
the speaker chooses that utterance
having observed the state and with some
value for that variable in mind okay so
you could think of this as an
interpretation for an ambiguous better
all of the work is done here at the
level of the pragmatic listener observes
just the utterance and has to jointly
infer what the state of the world is
that that utterance is supposed to be
describing and which value for V which
interpretation is intended for veterans
okay so here is a schema for an
ambiguous utterance right so suppose I
have some ambiguous utterance um I will
parameterize this interpretation
function by a B and I'll say if V is
true interpreted as one otherwise
interpreted as YouTube now this is a
non-trivial assumption about utterance
interact with interpretation functions
for now this is an approximation for
trying to model something like ambiguity
in language we can talk in more detail
at in the question period about what we
think might actually be going on
cognitively when it comes to things like
scope ambiguity so if you think there is
something like issues of syntax
determining which interpretations are
relevant then you probably don't want to
be parameterizing your interpretation
function to capture the different
syntactic derivations but for now this
is good enough to model the other as
disambiguation and we can think mostly
about what we actually want assuming
that we know what is actually going on
that's generating these interpretations
in the first place but for now here's
what the schema looks at okay so why is
this a lifted variable variant of the
RSA model because I have this
interpretation resolving variable V
which I have lifted up through the
speaker layer to the pragmatic listener
layer and that is where it gets resolved
so this variable is lifted from the
semantics up to the pragmatics lifted
variable now which utterances am i
dealing with I'm going to need to give
you some semantics to get some
predictions out of this model so suppose
I have my ambiguous utterance every not
every horse didn't jump over the fence
let's say if B then interpreted as none
of the horses jumped over the fence
otherwise interpreted as not all of the
horses what are the semantics for these
two unambiguous utterances here is none
so none is going to be a function from
States to truth values and it will
return true just in case the state is 0
just in case the state is none of the
horses jumped over the fence that's
where it will return true it will return
false for any other state not all is
also a function from States to truth
value
but now it's only going to return true
when the state is not equal to 3 it's
only gonna return so those are the
semantics that were assuming for the
unambiguous interpretations of this
otherwise ambiguous utterance so when I
feed this into my arts a model of
ambiguity resolution I've got a picture
that looks like this and what I'm trying
to do is infer whether or not I'm doing
with none or not all at the level of the
packet listener so I the pragmatic
listener here every horse didn't jump
over the fence and I have to do two
things I have to infer how many horses
don't over the fence and I have to infer
which interpretation was intended for
that which is not crazy when you think
about how we actually use language
that's all you the listener get okay but
that's not all because we also have to
capture the factor of Q D the question
under discussion so right now this model
is built with an implicit cutie right
now I'm modeling States as numbers of
horses who jumped over the fence so the
state could be 0 1 2 3 the literal
listener is inferring 0 1 2 3 literal is
referring how many horses jumped over
the fence listener is assuming we would
like other
here are some other cuties that we would
like to be able to model did all of the
horses jump over the fence did all the
horses succeed did none of the horses
jump over the fence do that of course to
succeed now in order to model these
bastards this has to get really
complicated so here is how the model
gets more complicated and so we have to
break the literal listener layer down
into two steps first the literal
listener does what you saw doing before
infer what the actual state of the world
is on the basis of the literal semantics
of the utterance and whatever
interpretation I'm going to use these
cuties as projections onto some others
here's how this was going to work with
the how many qud here is the semantics
for the havemany QD I'm gonna take in a
state and I'm gonna so the how many to
UD is going to tell you the did all of
the courses succeed QD is going to take
an estate and it will map that state to
true just in case that state is 3 just
in case all of the courses jumped over
the fence and it will not map it to
false otherwise so I have projected the
state from 0 1 2 3 to a boolean
true/false
the non qud is going to do something
similar only here it's going to map 0 to
true and everything else to false
ok so these are the semantics for the
questions that were assuming and now
what happens is okay I've inferred what
I think the state might be now I need to
apply the qud to that state in the case
of the how many QD I'm just going to get
that state back so I'm going to return a
distribution over 0 1 2 3 in the case of
the all and the none
you DS now I'm going to return a true or
false value that's what X is here so
it's going to be all of those states
that map to true all of those days that
map to false and now I'm going to return
a distribution okay so the literal
listener is now returning a distribution
over whatever the qud will return when
applied to the state what this means is
now the speaker observes the actual
state but now tries to calculate that
the listener will arrive at the correct
value of the community as applied to so
now I want to make sure that the literal
listener is going to get the correct
value of the QD with respect to the
state that I'm observing and the
pragmatic listener nothing has changed I
have to infer the QD now in addition to
what the state of the world is in which
interpretation but I'm still trying to
infer what the state of the world is
this is the full model
good so now what we want to do is
manipulate these factors the pragmatic
factors the grammatical factors and
generate predictions from the model how
are we going to manipulate these factors
suppose I want to manipulate your world
knowledge or your expectations where
your world knowledge controls how likely
you think it is that horses are to
succeed at jumping right so I want world
knowledge that says horses are great
jumpers world knowledge that says horses
are terrible numbers I'm going to
manipulate that by changing the state
prior so I'm going to make certain
states to the world more or less likely
so I could make world state 3 for
example the world state where all of the
horses succeeded really likely a
priority or I could make world state 0
the state of the world where no horses
succeeded really likely a very this is
how I can independently manipulate this
factor of moral knowledge and practice
the its effect on the behavior of the
model I can manipulate the QD
expectations by manipulating the prior
on the Qt so I could have a flat prior
where each of the cuties is equally
likely or I can have a prior rhythm any
to you D is the most likely or I can
have a QD where the all did all of the
horses succeed QD is the most likely
okay so that's how I can manipulate
independently this effect of the QD and
for the scope access this grammatical
processing factor I can manipulate which
of these scope values service or inverse
is more likely on priority so this is
how we're going to manipulate these
independent
try and observe some behavior mainly the
truth value judgments but we have to
think about what it is that we're
modeling what is the behavior in the
world that we are observing such that we
are trying to predict that behavior so
this is what we're trying to model Mary
said everywhere is didn't jump over the
fence
did Mary speak truthfully or not now if
you're not a linguist if you're not a
samantha cyst this is not something that
you do in your daily life this is not a
normal task this is very artificial and
strange what the hell are you doing when
you're trying to perform this task what
I'd like to convince you that we're
doing is deciding whether or not to
endorse that utterance as a description
of that state you see a state of affairs
you see an utterance would I choose that
utterance to describe that state of
affairs now this is something that we
know how to model this is speaker
behavior it's not listener behavior this
is speaker behavior I observe this state
of the world and now I have to choose an
utterance to describe this data form in
the truth value judgment task you have
two choices for utterances you have that
thing there and you have not that thing
there or saying nothing at all so I can
choose to endorse the other is or I can
choose to not endorse that utterance
stay silent and say you know what it's
better for you to just back off to
whatever prior knowledge you had going
into this situation as opposed to be
screwing it up with giving you this
crappy utterance this is a proposal okay
now if we go back to the model that we
had for how to rinse endorsement we're
not there yet because we have
are taught something that observes an
utterance and infers with the state of
the world is but I'm telling you that we
should be modeling speaker behavior
write what you want to speaker who
observes the state of the world and
chooses an utterance we don't want to
speaker who observes the state of the
world observes a specific value for the
scope it observes the specific to you
deep what we want is one layer here's
how to raise s2 observes the state of
the world and chooses an utterance to
communicate now to the pragmatic person
who is going to do the work of resolving
all of those other variables so I choose
some utterance to describe the state by
reasoning about the pragmatic listener I
should have also put the cost in there
because the s2 speaker is just as or
lazy now which utterances am I going to
give as options to this s2 speaker oh
that should be nice to hear this slide
is so that s2 speaker has two choices I
can say the ambiguous utterance every
not roll the dice and hope that that
pragmatic listener will get it right or
I can say nothing at all and what the
pragmatic listener is going to do is
just use his prior beliefs do no harm
so here is how we can generate
predictions out of this model you've got
a state of the world
what's the probability that you will
endorse that every non utterance to
describe that state of the world so in
simple terms here is what we're modeling
here's the state of the world that you
observed two out of the three horses
jumped what is the probability of
choosing every not over silence to
endorse this now what I'm going to do is
show you the predictions of the model as
I manipulate those factors and see which
of those factors have the largest effect
on this utterance endorsement behavior
such that we could blame them when it
comes to the really high endorsement or
the really low endorsement for adults
versus kids so model predictions what is
the probability of endorsing the
ambiguous utterance as a description of
this state of the world that's on the
y-axis higher values mean you're more
likely to endorse that utterance if you
want to map this on to truth value
judgment behavior you're more likely to
say yes true whatever it is give the
thing a cookie
however they doing so higher values mean
that you're more adult-like
lower values and even your morning
I'm starting here with the grammatical
factor of the scope of private and when
I'm logging on the x-axis is the prior
probability of the inverse
interpretation the not all
interpretation so I could have a prior
probability of 0.1 it's very unlikely to
get that inverse interpretation or all
the way up to 0.9 it's really likely to
get that inverse interpretation okay so
as you traverse the x-axis from the left
to the right you're moving from really
strongly favoring the surface none to
really strongly favor
I should have done it this way really
strongly favoring the service none to
really strongly favoring inverse zoom
and what did that mean right and that's
the proposal so did this did the puppet
speak well or not give the puppet well
then yes I would use that utterance to
describe the state of affairs this
puppet did not speak well no I would not
use this utterance to describe this
table actually and that's what you're
getting
my access so we see some effect of this
grammatical factor if inverse scope is
just super likely a priority you are a
little bit more likely to endorse the
utterance but we're not anywhere close
to child versus adult just with scope
alone so we're probably going to need
some more help
now here's a look at the world knowledge
manipulation so what you have on the
x-axis is the strongly favored state in
the state prior so I could have a
uniform state prior where 0 1 2 & 3 are
all equally likely states as I go into
this situation I don't have any strong
beliefs about forces and they're jumping
I could have a very strong belief that
horses are really crappy jumpers I could
have some intermediate beliefs horses
are okay or I could believe that horses
are really really good jumpers really
likely for horses to succeed
so these favored parameter values get a
prior probability of 0.9 in this
distribution we split the probability
now I think they're starting to get a
little more excited now as I go from
believing that horse is a really bad
jumper is to believing the horses are
really great jumpers increasing
endorsements lastly you have the qud
manipulation or the goal prior so again
on the x-axis I'm starting with the
uniform QD prior they're all three
equally likely and then I'm selectively
favoring one of those cuties over the
others so first I really think that the
QD is didn't none of the horses succeed
or did any horse succeed those things
are gonna work out to be I could have
the default beauty how many horses
succeeded or I could have me did all the
horses succeed what we notice is as I
moved from the did any more succeed to
did all the vs. 60
I am drastically increasing so this poor
scope prior over here doesn't look as
exciting as the other two factors what
we notice is that the two pragmatic
factors seem to have a much larger
effect on this utterance endorsement
than this grammatical factor of scope
axis which is curious because me as a
linguist as a semesters going into this
I would think well it all depends on
which scope you're getting for this
thing so of course that's going to have
a large effect maybe not maybe these
pragmatic factors are even more
important and that would make sense
given the effects that we are measuring
in these experiments where we are
manipulating pragmatic factors by
manipulating pragmatic factors in these
experiments we are drastically
increasing utterance endorsement rates
now most interesting for me amused is
this plot here where we see that the
pragmatic factor is completely
overwhelmed the grammatical processing
factor so here I had set the world
knowledge and the QD priors such that I
believe that horses are great numbers
and I think that the QD is did all of
the horses job on the x axis I'm
manipulating that scope product going
from I'm really likely to get the
service goat - I'm really likely to get
the Emperor scope and it has nice to
know the pragmatic factors
moment they overwhelm it because
endorsing the utterance requires no
disambiguation at all what could I
possibly mean by that if I'm trying to
decide whether or not all of the horses
jumped I could tell you every horse
didn't jump over the fence and either
interpretation none we're not all gives
you a full answer to that question the
answer is no you don't have to
disambiguate the utterance that is a
great uh pterence
under either interpretation so of course
you should endorse it if I know that you
the listener believe that horses are
really really great jumpers if you
expect that all of those horses are
likely to succeed then for me to
convince you that your prior believes
your expectations do not hold that
ambiguous utterance is really useful
under either interpretation under none
or not all you know it is not the case
that all of the horses chopped so
informative 'ti is ruling the day here
when it comes to this utterance
endorsement in these cases
great that I can endorse it's going to
be informative it's going to either
fully answer that question or it's going
to inform me that what I thought was the
case is not the case this was the aha
moment before us this was when we said
oh my goodness what are we learning from
truth value judgments if not which scope
interpretation people are getting it can
be the case does not require
disambiguation so this is where I wind
up at the I'm not sure whether or not
I'm endorsing truth value judgments or
not right because when it comes to
trying to explain this behavior adults
are really likely to endorse this
utterance kids are really unlikely to
endorse this utterance I have shown you
that endorsing the utterance doesn't
require disambiguation what it requires
is the ability to manage the pragmatics
context so if you want to be looking for
deficits and kids you should be looking
for pragmatics so endorsing the other
ends requires no disambiguation you need
good pragmatics kids don't have good
pragmatics that's not a surprise so
where do we go from here well we have
this model that is making some really
nice fine grained quantitative relations
about behavior where we can now turn
these little knobs for each of these
Digital factors and test not just
qualitative predictions the quantitative
predictions so to robustly test this
model what we can do is attempt some way
to manipulate the priors like we were
doing in the model to see whether or not
they have the empirical effects that
we're predicting from that model in the
worst it's not trivial to try and
manipulate people's world knowledge
going into an experiment these priors
are pretty closely held and it's hard to
push them around if you have any
suggestions we're all yours if you have
suggestions on how to manipulate vision
scope prior I would love to hear that
one in a way that is not going to
manipulate the other factors I have yet
to encounter that now in general I think
that what I find so exciting about this
model this family of models is that it
gives you a concrete proposal for how it
is that we handle ambiguity how it is
that we resolve in you receive you
observe an utterance that is potentially
ambiguous and you reason about the state
of the world that that uh pterence is
supposed to be describing while you are
actively reasoning about which
interpretation was intended now what's
interesting about this model is that yes
we are attributing this sort of
reasoning to these kids so if you want
to object to that I would not find that
objection unwarranted however this model
does a really good job of capturing the
kids behavior so maybe it's not so crazy
to think that kids can engage in this
sort of recursive social reasoning the
more research that comes out about kids
in theory - so the reasoning seems to
suggest that they're not as dumb as we
thought they were
so maybe it's not so crazy now what's
also exciting about this model is there
were cases where adults are pretty kid
like themselves so if I tell you that
there were two frogs and one frog jumped
over a rock and the other frog did not
and then you hear the utterance two
frogs didn't jump over the rock would
you endorse that
so most adults do not if you perform the
same sort of experimental manipulations
of you suppose the contrast on the other
bells and whistles the endorsement rates
go up
so maybe adults are engaged in the same
sort of reasoning as kids which would
suggest that we've got continuity in the
development of this disambiguation
mechanism we don't need any sort of
qualitative shift and development from
kid to adult we're all doing the same
thing however adults are much better
able to manage the pragmatic context and
they are less susceptible to new
information because their priors are
more robust so now you have the
cautionary tale for interpreting truth
value judgments before you can start
interpreting truth value judgments
you've got to understand the pragmatics
that goes into giving those judgments
and we can



## Keywords:
