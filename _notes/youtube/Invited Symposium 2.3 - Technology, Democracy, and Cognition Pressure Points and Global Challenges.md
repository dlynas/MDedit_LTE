---
note_type: metamedia
mm_source: youtube
mm_url: https://www.youtube.com/watch?v=yQlYCei7vEQ
---

# Video
Invited Symposium 2.3 - Technology, Democracy, and Cognition Pressure Points and Global Challenges
![](https://www.youtube.com/watch?v=yQlYCei7vEQ)

## Transcript:
we're going to have to move on and the
next speaker is Steve Lewandowski
from the University of Bristol who will
be speaking on another
terrible Global challenge we face that
is very related to Dave's so Steve why
don't you take it away
okay thank you and I hope you can see
yes uh apparently in my slides show okay
my job today was to give you a broad
overview of the relationship between
online technology and democracy
um and and how their pressure points
between human cognition and the online
environment that have adverse
consequences
um we think for uh democracy and based
on a recent analysis that my colleagues
and I published we've identified four
such pressure points and in 15 minutes I
can't go through all of them so I will
focus on just two namely what's known as
the attention economy which David just
uh hinted at at the end of his talk and
algorithmic content curation and I just
want to talk a little bit about what
that means what the implications are and
what we can do about it focusing in
particular on algorithmic content uh
curation
so what's the attention economy wow the
attention economy is basically
your online environment whenever you go
on Facebook or on Twitter or Instagram
or whatever it is
um your attention is the main product
online now that's not always true but it
is very much true uh on social media and
as a rule of thumb if anything is free
online then you're being sold then you
are as the customer the user you're the
product whose attention is being sold
and the dwell time of a person on a
platform translates into advertising
revenue and that is why all the
platforms have little features to keep
you there for longer than you might
otherwise the stage uh one prime example
is the autoplay feature on YouTube which
means that a video just keeps running
um even one that you haven't chosen it
just automatically quickly shows up and
you can spend hours just watching videos
that you never selected on YouTube and
of course being exposed to ads
throughout now
I think on the one hand this is terrific
it has created many free services like
Google Maps uh other things that are
indispensable to our lives but it comes
at a cost and the cost comes out of our
basic human attention or biases which
are listed here some of them so we tend
to attend to emotional stimuli uh in
particular to negative emotions
and there's an old sort of saying and
journalism that you know if it believes
it leads you put it on the front page of
the tabloids to get people's attention
so this has long been known but of
course now we are in an uh economy where
that can be exploited by people who are
producing disinformation and the reason
this is so is shown in this graph which
I have to explain this was done by
somebody in our
who looked at 160
000 full-text news articles they were
chosen because they had been retweeted
by members of the U.S Congress
um and he performed the computational
text analysis to determine the emotional
slant of each of those hundred and sixty
thousand full text articles and he then
related the emotional slam to the
quality of the domain and the graphs
you're seeing here are showing quality
on the y-axis and intensity of emotional
slant on the x-axis and if you focus on
the negative emotions anger disgust fear
negative generally sadness and so on
then you find that the more of that
emotion is present the less uh reliable
is that new source uh on average and the
problem is that the platforms make more
money from the highly emotive articles
or content because that is what people
preferentially uh attend to so here's
the media translation of the commercial
imperatives of the platforms into lower
quality of information and this is
something obviously we're going to have
to deal with now unfortunately right now
it's the only thing I can mention about
the attention economy let me move on to
the algorithmic content curation
um which is also
sometimes known in the extreme case as
micro targeting now again
this is a double-edged sword on the one
hand having recommendous systems that
tell me on Amazon what other book
s uh are terrific I mean I love Amazon's
back in addiction so I can't help I'd
love to buy all the books they they say
I should look at because they know what
I want but the problem is if I want
something that is bad for democracy then
yes they will also recommend that to me
namely increasingly extremist or
radicalizing uh content and this is
non-trivial because we have a lot of
data from lab experiments showing that
recommender systems and so on and
causally influence our preferences and
perceptions and given that about a third
of all videos consumed on YouTube were
never chosen by the user we have to be
concerned about the impact that may have
might have in particular when it comes
to ads uh mainly in the political domain
now talking about advertising briefly
the best ad is the one you only show to
people who are going to buy your product
if you show an ad just somebody doesn't
buy your product you've wasted money and
we all lose because prices go up because
advertising costs are increased so it's
an hour interest collectively as a
society for ads to be targeted at the
people who are most likely to buy a
particular product now that's been the
case for a long time you're not going to
see too many cosmetic ads and motorcycle
magazines magazines for example this is
audience segmentation that has been
around forever but what hasn't been
around forever is that you can infer
users personalities and then allow
advertisers to Target People based on
their personality here's a patent that
Facebook has which uh is is very open
about it you know we infer your
personality and that we target
advertisements and messages
um to users the empirical evidence for
that is very clear if I have 300
Facebook likes I know that person better
than their own spouse there's a machine
learning study that has shown that and I
can then
Target people on the basis of their
personality does this work the so-called
micro targeting well here's a study from
some time ago that in my opinion made
that case very nicely there are two ads
here for your cosmetic products and the
one on the left it turns out appeals to
people who are extroverted the one on
the right appeals to people who are
introverted and if you can now direct
these ads on Facebook to people whose
personality you know from their likes
then you can maybe sell products more to
people if the ad matches their
personality is that true well yes in
this particular study
that was the case I can show you the
data and explain the design at the same
time basically they showed ads that were
targeting introverts and extroverts
introverts and green extroverts in blue
they target that two new audience that
was either matched to a mismatched and
you can see instantly that if the uh ads
match the audience then the conversion
rate is that is the actual number of
clicks that people act on on the ads
that is higher when the ads match than
when they don't and there's other
studies showing the similar thing so we
do know that targeted advertising is
very effective
now
I'm not terribly concerned about
Cosmetics to be honest but I am very
concerned about uh political messages
that might be micro targeted to People
based on their personality
for the reasons listed here because this
is happening without the people really
being aware of it it is a cons it's
concealed because you don't know that
you're being targeted
um if messages are targeted to segments
of an audience in in the extreme case to
a single individual then you can't
promote that you cannot have a
democratic debate if it has taken place
uh furtively and and you know in secret
between people who issue ads and others
that are being targeted so there are
some serious problems in my opinion with
political micro targeting and the
question is what can we do about it
other than legislate against it well my
colleagues and I have explored two
options to deal with micro targeting I
want to talk about both of them briefly
uh one approach is to boost users
knowledge about themselves
I'm not going to show you very briefly
an experiment where we got people's
introversion extroversion score and a
brief questionnaire we then gave them
feedback about their score
um Sean here uh you're this person was
extroverted you know blah blah blah
here's his score this is how you compare
to other people once they knew that
score in the experimental condition they
were presented the ads from the study I
already explained which were designed to
appeal to extroverts so introverts so
the task now in this experiment for
people was to decide whether or not they
were being targeted and we knew their
scores so we could pick out how
accurately they were able to identify
that they were being targeted
well and here are the data it turns out
that if you give people feedback about
their personality and explain it to them
if you boost their abilities to
recognize themselves their accuracy in
detecting that they're being targeted
it's about 30 percent higher than that
isn't a control condition where no such
feedback was provided in other words in
in something like a minute or two we can
train people to know when they're being
targeted on the basis of their
personality using up to now cosmetic ads
which I said are terribly important but
of course we're currently working on
expanding this
um to political material and one way in
which we're extending this to political
material is by designing machine
learning tools that are alerting people
when they might be micro targeted how
does that work well the goal here is to
provide some Plug-In or other tool that
alerts users that when they're being
exposed to messages that are so
consonant with their values and their
personality that it's almost too good to
be true in other words hang on you're
being sent a message that is so aligned
with your personality that maybe
somebody is trying to manipulate
that's the goal and can we do that well
yes we can uh we have a machine learning
algorithm that can associate personality
or house Associated personality with
consume text
um there's a complicated methodology in
the background here that I don't have
time to explain but the bottom bottom
line is we have a small but
reasonable effect size and Effectiveness
in being able to alert people
when they're exposed to messages that we
think are likely
or at least possibly designed to be
consonant with their personality beyond
what might be expected by chains and
that gives people the choice
to then uh look at this message with a
more critical eye which is our goal in
doing this so
conclusions of my the focal point of my
talk about micro targeting yes it is
possible there is no question about it
uh it is also effective there's a number
of studies that show this to my
satisfaction and it is problematic when
it comes to political content foreign
people something about themselves the
other one is through machine learning
tools and of course the the third one
the third way of dealing with it is
through regulation
and just if you're interested in this I
can pop the link in the chat I um I was
responsible for a report for the um uh
European Union that came out about a
year and a half ago and where we
outlined the basically everything I've
talked about today
and that
um proposes some solution to this
through clever regulation without
introducing censorship and the EU is in
fact working on that right now and has
two initiatives that have just been
passed that in part uh are looking at
some of these recommendations and with
that I think I took an extra minute
sorry for that I want to thank my
funders and collaborators and I look
forward to your questions
awesome thank you Steve
we have time for a couple questions so
anyone in person if you want to line up
by the microphone
um go ahead or on chat if uh you have
questions there
um
while we're waiting I'm going to start
off with uh an evil one for you Steve
um which is so the thing that I keep
thinking like on the one hand they're
what you might call individual level
Solutions like sort of teaching people
to be aware of when they're being
manipulated and so forth and then
there's also systemic kind of level
Solutions like regulations and
on balance what like what does success
require what kind of mix of these things
where should we be focusing our efforts
the most
well I undoubtedly on the on the
systemic uh end I mean there's no
question in my mind that what we can do
is cognitive scientist is you know
incremental and it's helpful and of
course we should do it you know we
should teach people this
etc etc but that's not going to solve
the problem by itself we also as I think
David has said you know you got to get
the platforms engaged in uh making sure
that you know they're not favoring low
quality information in the first place
you know that that really is is is the
the tricky issue that they're not making
money out of destroying democracy you
know it's as simple as that we got to
break that link and right now I would
argue that that link is well you know
strong enough for concern
yeah
all right great I mean not great but
thank you
um any other questions
okay I see one person go ahead hi
Bender from
I really appreciate this word
word problems
I have a very specific question though
in the study where you showed how you
could sensitize people to whether or not
they're being targeted do you have
evidence that that persists those two
minutes of training or is it just a
short-term effect
good question I don't have
um evidence from this particular study
about the longevity of of the effect
however
um we have done a large number of
studies within this domain of boosting
in inoculation uh where we've shown that
these effects last surprisingly long now
this is now not personality it is about
inoculating people against misleading
rhetoric but we have a paper in the
pipeline where we show that that you
know we can we can take this out to
months and if we have little booster
shots of of these you know repeated
30-second treatments then uh there there
is you know competence remains very high
and even without that uh we're talking
about several weeks when it when it can
still be shown to be effective so which
is which is remarkable but we've also
got a paper coming out in August
um in in science advances where we've
done a big study on YouTube using this
inoculation with just a single 30 second
intervention and
um you know that lasts for up to 24
hours very uh reliably we can pick it up
statistically quite was quite a
reasonable effect so it doesn't just
disappear in seconds
great thank you and that actually is
great
um uh thanks again Steve


## Keywords:
