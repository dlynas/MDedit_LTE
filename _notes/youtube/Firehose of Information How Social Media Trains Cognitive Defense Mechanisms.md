---
note_type: metamedia
mm_source: youtube
mm_url: https://www.youtube.com/watch?v=1auf-K1DkiA
---

# Video
Firehose of Information: How Social Media Trains Cognitive Defense Mechanisms
![](https://www.youtube.com/watch?v=1auf-K1DkiA)

## Transcript:
so one feature of the modern day that is
completely new in human history is just
the amount of
information coming our way in this video
i'm going to be laying out
an argument that social media platforms
and social media algorithms
have trained our brains to
label and dismiss information that
is too new or too threatening or too
different from our world views that
that's good for a social media platforms
and it's actually something that's
somewhat necessary in the sense that
we have to have a way of dealing with
the fire hose of information that's
coming our direction
so it's not entirely bad and some of the
labeling and dismissing
is labeling and dismissing that should
happen
but i'm going to make the argument that
that's starting to affect our
relationships in the real world in a
negative way so first of all
we do have a constant influx of
information
unlike anyone throughout history if you
rewind a hundred years
and look at how much information do
people consume in their lifetimes
through the newspapers or through
conversations or whatever probably the
same amount of information that we would
consume
in a week was what they would consume in
a whole lifetime
and people have started calling this a
fire hose of information
and misinformation and i think that's a
really good term for it because we can't
possibly take all of that in
so economists like to think about scarce
resources
time is a scarce resource but so is
cognitive energy
you can't be engaging cognitively at a
high level all day long there's sort of
only a certain number of hours per day
that you can do that so you have to
decide how am i going to spend my
cognitive effort
and which pieces of information that are
new or surprising or threatening
am i going to spend my my thinking time
thinking about so given that let's think
about this from the social media
algorithms perspectives
and the algorithms are given one task
which is to maximize engagement
now engagement has different formats
there's different ways of measuring
engagement
there's time on platform number of
clicks
number of likes number of thumbs up
signs there's different ways of
measuring engagement
and the algorithms are just given a
multitude of pieces of information
about our engagement and the way that
engagement gets monetized
and they're just told to maximize
profits so the algorithms themselves
don't have negative intentions but
they're going to sort of go through this
guess and check process
and it's an evolutionary process where
the beliefs of the algorithm get
get updated and get improved over time
as they see how different
guess and check techniques work out so
how does that relate to this fire hose
of information
well the firehose is actually going to
create a paradox i think
for these algorithms on one hand
when people constantly have information
coming at them
and especially if that information is
threatening which a lot of it might be
if you want people engaged if you want
them to click
if you want them worried and spending
time on the platform to sort of assuage
their worries
threatening information might actually
accomplish that
so on one hand it's good to give them
lots of information because that is how
you keep them engaged
on the other hand this much information
can be overwhelming to people in a way
such that they just
shut down the platform disengage
and don't want to deal with all of this
constant threatening information as a
matter of fact we do see people who
take breaks from social media that's
becoming a more common thing
and it's probably a pretty good trend
but right now we're thinking about the
social media algorithms
perspective and the algorithm doesn't
want them to disengage
so how does the algorithm balance out
giving people information including some
threatening information
or information that's different from
their own world view
and still keeping them on the platform
well here's my hypothesis i think the
social media algorithms
have figured out through a guess and
check process that
if they give us the cognitive armor
to encounter that much information so
that we can dismiss
information easily that we don't want to
deal with
then that keeps us engaged for longer
while still throwing all this useful
information at us
that that keeps us on the platform and
just to be clear i do think it is
absolutely necessary for us to figure
out which information to dismiss
and there's different ways of doing that
i'm probably going to do another video
on
sort of the economics behind
cost-benefit analysis for
good and bad techniques for doing that
for example you could outsource the
curation of your information
to experts you could outsource the
curation of
information to crowds maybe
a certain type of crowd like people like
you
you could decide what to dismiss or not
dismiss based on
how the headline made you feel or you
could come up with a more complicated
set of rules for which types of
information to dismiss or not dismiss
and you could be thoughtful about that
and
being thoughtful about that is probably
good and necessary and we probably
actually do need to come up with better
techniques
for figuring out what new potentially
world view changing information do we
actually spend time
thinking through so so that's something
i'll
i'll talk about in another video this
video is really about
how does this cognitive armor stuff work
well let's think through what cognitive
armor might look like it's basically
a label and dismiss you you want sort of
a series of labels that you have in your
back pocket that you can just sort of
stamp the label on a headline that's
threatening and just say
nope that's invalid i'm not going to
think about it nope that's an
issue and there's all kinds of labels
that'll work for this
drama queen overly sensitive conspiracy
theory
that person has a horse in the race
that's pseudoscience
that's motivated reasoning that's biased
that's ignorant
that's a self-serving perspective that
person's pretending to be more important
than they
are that person's not a real authority
that person is too old to understand
that person's too young to understand i
mean you could go on and on you kind of
get the idea there's these sort of
labels
where if we can encounter something that
we don't want to be true
or that would really upset our worldview
in some way
we just have labels to slap it on that
headline
and then it's gone it's dismissed and
then we can move on into our interaction
with social media that we like to
encounter
in a way that's more comfortable and
more
fulfilling and it's worth noting that
this can be done by just
you applying the label to the headline
you don't like or it can be done where
maybe you don't feel fully comfortable
dismissing that headline but you have
sources that are kind of within your own
worldview
that if you go to those sources you can
find
someone who will dismiss that headline
fast enough enough for you so this can
come from you
or it can come from experts who do the
labeling and dismissing
for you so that you're more comfortable
and more secure
in your labeling and dismissing of new
information that challenges your
worldview
all right now i'm going to talk about
three problems with this
and the first one is the one that i'm
most worried about which is that
i think people are using this a lot to
dismiss
people in their lives and when we shut
people down
too much or too often it can cause us to
sort of
not want to share and that closes out
the possibility of intimacy
in a way that's more profound than i
think we're aware of at this moment
so if the social media platform is going
to train our brain to dismiss
by perhaps giving us experts who dismiss
and we sort of pick up the hat the
thought patterns of those experts then
we kind of do this automatically oh nope
that's a bad piece of information
shut it down we're done however when
you're with a person
face to face looking them in the eye
and they share something that's been on
their mind
which might be something that they read
on social media and have been thinking
about
and if you encounter that piece of
information with that real human being
in the same way you encounter
that piece of information if it were in
your news feed by sort of
labeling it dismissing it done
the person in front of you is going to
feel shut down
they're going to feel dismissed and
depending on the label
that you label that piece of information
they might
feel like you're treating them with
contempt if it's sort of like oh that's
stupid
oh that's overly sensitive or
exaggerated people are gonna feel
dismissed as a person
by that and what do you do when you feel
dismissed or when you feel someone's
treating you with contempt well there's
two basic responses
one is that you you treat them with
contempt back
there's something about contempt that
sort of invites more contempt
such that it escalates so that's one
thing that's happening
i think the thing that's actually
happening more often though is that
people
they shut down they say you know what
i'm not gonna
share what i'm thinking about i'm not
gonna share what's on my heart
because then i'm gonna be dismissed as a
person my thoughts my experiences are
gonna be dismissed
so i'll just not even try to share with
anyone
unless i know that they have a similar
um way of interacting with information
such that they're not gonna shut me down
because vulnerability is risky and when
we try to be vulnerable with our
thoughts and fears and we're dismissed
like that
it's just really easy to go into hiding
so there's this book i read recently by
vivek murthy it's called together and
the book basically makes an argument
that people need other people we need
this
these social relationships but we're not
getting them there's a lot of loneliness
out there
and he talks a lot about sort of
situations where you put people together
and they interact well and they thrive
but i don't think it's that simple i
think a lot of times you put
people together and sometimes they feel
even more lonely
so just getting people in the same room
doesn't seem to quite work
and i think part of that is that this
dismissing of people is happening so
frequently
that unless you have a very well matched
social media feed and way of dismissing
information
with someone you end up shutting down
and not wanting to share
and then in some ways kind of acting
fake with those people
which is the opposite of intimacy so
that's
the first problem with this sort of
cognitive armor
that i do think we're being trained in
an almost pavlovian way
by social media algorithms the second
problem with this
cognitive armor that requires us to have
easy ways of labeling and dismissing
information we don't want
is that we're gonna seek out experts who
are going to help us
label and dismiss because then we can
sort of
soothe the fears that might otherwise
come up as we're
interacting with so much information
that means that
the social media figures who end up
being most successful
might be those who are really good at
labeling and dismissing
information that would be new to your
world view or information that might
make us feel uncomfortable but of course
we realize that
sometimes really important information
is
uncomfortable is the type of information
we might want
to dismiss and if we build up
habits of dismissing that type of
information
we're not going to see the world in an
accurate way so i
am really worried that the types of
people who will be
really successful on social media will
be people
who are good at convincingly dismissing
information that would be threatening to
people's worldviews
i guess i could say more about that but
this video is probably long enough
so i'll stop but i really hope that this
has gotten you thinking about
how might social media algorithms train
our brains
to interact with their platforms in a
way where we can encounter
this constant influx of information
without getting too overwhelmed by it
and i do think there are good and
healthy ways of
sifting through information but that the
financial incentives of the algorithms
might be not the having a more healthy
and strategic way of
sort of encountering a new piece of
information and being like
actually is this one that i need to
think more deeply about and perhaps
even update my own beliefs or is this
something that i really should
dismiss and not give another second
thought to
so i'll do a video on on approaches for
that as well


## Keywords:
